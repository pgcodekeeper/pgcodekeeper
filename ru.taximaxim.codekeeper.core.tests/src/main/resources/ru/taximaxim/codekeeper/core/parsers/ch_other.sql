ALTER NAMED COLLECTION foobar03 DELETE b;
ALTER PROFILE s1_01294 SETTINGS readonly=0;
ALTER PROFILE s1_01294 TO u1_01294;
ALTER PROFILE s1_01294, s2_01294 SETTINGS max_memory_usage=6000000;
ALTER PROFILE s2_01294 SETTINGS readonly=1;
ALTER PROFILE s2_01294 TO NONE;
ALTER PROFILE s2_01294, s3_01294, s4_01294 TO r1_01294;
ALTER PROFILE s3_01294 SETTINGS NONE;
ALTER QUOTA q1_01297 FOR INTERVAL 5 DAY NO LIMITS;
ALTER QUOTA q1_01297 KEY BY user_name;
ALTER QUOTA q1_01297 TO u1_01297;
ALTER QUOTA q1_01297, q2_01297 FOR 1 day TRACKING ONLY TO r1_01297;
ALTER QUOTA q2_01297 FOR INTERVAL 30 MINUTE TRACKING ONLY;
ALTER QUOTA q2_01297 KEY BY client_key, user_name;
ALTER QUOTA q2_01297 RENAME TO 'q2_01297_renamed';
ALTER QUOTA q2_01297 TO NONE;
ALTER QUOTA q3_01297 FOR INTERVAL 2 HOUR MAX errors = 10, FOR INTERVAL 1 HOUR MAX queries = 70;
ALTER QUOTA q3_01297 NOT KEYED;
ALTER QUOTA q4_01297 FOR RANDOMIZED INTERVAL 2000 SECOND errors MAX 5;
ALTER QUOTA q5_01297 FOR 1 YEAR MAX errors = 111;
ALTER SETTINGS PROFILE s1_01294 SETTINGS INHERIT 'default' TO NONE;
ALTER SETTINGS PROFILE s2_01294 RENAME TO 's2_01294_renamed';
ATTACH TABLE 01686_test;
ATTACH TABLE adaptive_granularity_alter1;
BEGIN TRANSACTION;
CHECK TABLE check_codec SETTINGS max_threads = 1;
CHECK TABLE check_query_log;
CHECK TABLE check_query_test SETTINGS max_threads = 1;
CHECK TABLE check_query_test_non_adaptive SETTINGS max_threads = 1;
CHECK TABLE check_query_tiny_log FORMAT Null SETTINGS max_threads = 8, check_query_single_value_result = 0;
CHECK TABLE check_query_tiny_log PARTITION tuple();
CHECK TABLE check_query_tiny_log;
CHECK TABLE check_table_with_indices SETTINGS max_threads = 1;
CHECK TABLE merge_table_standard_delete;
CHECK TABLE mt_table PART '201801_1_1_0';
CHECK TABLE mt_table PARTITION 201902 SETTINGS max_threads = 1;
CHECK TABLE mt_table SETTINGS max_threads = 1;
CHECK TABLE mt_without_pk SETTINGS max_threads = 1;
CHECK TABLE replicated_mt_without_pk SETTINGS max_threads = 1;
CHECK TABLE sqllt.table FORMAT Null;
CHECK TABLE t_large;
CHECK TABLE t_light;
CHECK TABLE t_source_part_is_intact SETTINGS max_threads = 1;
CHECK TABLE t_sparse_02235 SETTINGS check_query_single_value_result = 0, max_threads = 1;
check table tp settings check_query_single_value_result=0, max_threads=1;
commit;
CREATE NAMED COLLECTION 02918_json_fuzzer AS json_str='{}';
CREATE OR REPLACE DICTIONARY test_01915_db.test_dictionary (   id UInt64,   value String ) PRIMARY KEY id LAYOUT(DIRECT()) SOURCE(CLICKHOUSE(DB 'test_01915_db' TABLE 'test_source_table_1'));
CREATE OR REPLACE DICTIONARY test_01915_db.test_dictionary (   id UInt64,   value_1 String ) PRIMARY KEY id LAYOUT(HASHED()) SOURCE(CLICKHOUSE(DB 'test_01915_db' TABLE 'test_source_table_2')) LIFETIME(0);
CREATE OR REPLACE FUNCTION 02101_test_function AS x -> x + 2;
CREATE OR REPLACE FUNCTION 02125_function_2 AS x -> x + 1;
CREATE OR REPLACE FUNCTION 02148_test_function AS () -> (SELECT 2);
CREATE OR REPLACE FUNCTION 02148_test_function AS () -> (SELECT value FROM 02148_test_table LIMIT 1);
CREATE OR REPLACE TABLE alias_local10 (  Id Int8,  EventDate Date DEFAULT '2000-01-01',  field1 Int8,  field2 String,  field3 ALIAS CASE WHEN field1 = 1 THEN field2 ELSE '0' END ) ENGINE = MergeTree(EventDate, (Id, EventDate), 8192);
CREATE OR REPLACE TABLE distributed (x Array(Int8)) ENGINE = Distributed(test_shard_localhost, currentDatabase(), local);
create or replace table t1 (n UInt64, s Nullable(String)) engine=MergeTree order by n;
create or replace table t1 (n UInt64, s String) engine=MergeTree order by n;
CREATE PROFILE s10_01294 SETTINGS INHERIT s1_01294, s3_01294, INHERIT default, readonly=0, max_memory_usage MAX 6000000;
CREATE PROFILE s1_01294 SETTINGS NONE;
CREATE PROFILE s1_01294 SETTINGS readonly=1;
CREATE PROFILE s1_01294 TO NONE;
CREATE QUOTA q17_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '1.5';
CREATE QUOTA q1_01297 FOR INTERVAL 1 MINUTE MAX query_selects = ' 12 ';
CREATE QUOTA q1_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '-1';
CREATE QUOTA q1_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '0';
CREATE QUOTA q1_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '1 1';
CREATE QUOTA q1_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '12K';
CREATE QUOTA q1_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '18446744073709551615';
CREATE QUOTA q1_01297 FOR INTERVAL 5 DAY MAX ERRORS = 3;
CREATE QUOTA q1_01297 KEYED BY user_name FOR INTERVAL 1 minute MAX query_selects = 1 TO r1_01297;
CREATE QUOTA q1_01297 KEYED BY user_name TO r1_01297;
CREATE QUOTA q1_01297 NOT KEYED;
CREATE QUOTA q1_01297 TO NONE;
CREATE QUOTA q1_01297, q2_01297 FOR 1 day MAX errors=5;
CREATE QUOTA q1_01297;
CREATE QUOTA q3_01297 FOR INTERVAL 1 MINUTE MAX query_selects = ' 12k ';
CREATE QUOTA q3_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '12M';
CREATE QUOTA q3_01297 KEY BY ip_address;
CREATE QUOTA q3_01297 KEYED BY client_key, user_name FOR 0.5 YEAR ERRORS MAX 11, QUERIES MAX 100, FOR 2 MONTH RESULT ROWS MAX 1002;
CREATE QUOTA q3_01297 TO r1_01297;
CREATE QUOTA q4_01297 FOR 1 WEEK TRACKING ONLY TO ALL EXCEPT u1_01297;
CREATE QUOTA q4_01297 FOR 2000 SECOND errors MAX 5;
CREATE QUOTA q4_01297 FOR INTERVAL 1 MINUTE MAX execution_time = ' 12k ';
CREATE QUOTA q4_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '12Mi';
CREATE QUOTA q4_01297 KEY BY client_key;
CREATE QUOTA q4_01297 KEYED BY none FOR 1 hour NO LIMITS;
CREATE QUOTA q4_01297 TO u1_01297;
CREATE QUOTA q5_01297 FOR INTERVAL 1 MINUTE MAX execution_time = ' 00 ';
CREATE QUOTA q5_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '12G';
CREATE QUOTA q5_01297 FOR RANDOMIZED INTERVAL 1 YEAR MAX errors = 11, MAX queries = 100;
CREATE QUOTA q5_01297 KEY BY client_key, user_name;
CREATE QUOTA q5_01297 TO r1_01297, u1_01297;
CREATE QUOTA q6_01297 FOR 2 MONTH MAX errors = 11, queries = 100, result_rows = 1000, result_bytes = 10000, read_rows = 1001, read_bytes = 10001, execution_time=2.5;
CREATE QUOTA q6_01297 FOR INTERVAL 1 MINUTE MAX execution_time = ' 00 ';
CREATE QUOTA q6_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '12Gi';
CREATE QUOTA q6_01297 KEY BY client_key, ip_address;
CREATE QUOTA q6_01297 TO ALL EXCEPT r1_01297;
CREATE QUOTA q7_01297 FOR 1 QUARTER MAX errors 11, queries 100;
CREATE QUOTA q7_01297 FOR INTERVAL 1 MINUTE MAX execution_time = ' 00k ';
CREATE QUOTA q7_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '12T';
CREATE QUOTA q7_01297 KEYED BY 'none';
CREATE QUOTA q7_01297 TO ALL EXCEPT r1_01297, u1_01297;
CREATE QUOTA q8_01297 FOR 0.5 year ERRORS MAX 11, QUERIES MAX 100, FOR 2 MONTH RESULT ROWS MAX 1002;
CREATE QUOTA q8_01297 FOR INTERVAL 1 MINUTE MAX execution_time = ' 00k ';
CREATE QUOTA q8_01297 FOR INTERVAL 1 MINUTE MAX query_selects = '12Ti';
CREATE QUOTA q8_01297 KEYED BY 'user name';
CREATE QUOTA q9_01297 FOR INTERVAL 1 MINUTE MAX execution_time = ' 00123k ';
CREATE QUOTA q9_01297 FOR INTERVAL 1 MINUTE MAX execution_time = '12K';
CREATE QUOTA q9_01297 KEYED BY 'IP_ADDRESS';
CREATE QUOTA sqllt_quota KEYED BY user_name TO sqllt_role;
CREATE SETTINGS PROFILE sqllt_settings_profile SETTINGS interactive_delay = 200000;
CREATE UNIQUE INDEX idx_tab2_0 ON tab2 (col1);
CREATE WINDOW VIEW test_01048.wv ENGINE Memory AS SELECT count(a) AS count FROM test_01048.mt GROUP BY b, hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW test_01048.wv ENGINE Memory AS SELECT count(a) AS count FROM test_01048.mt GROUP BY b, tumble(timestamp, INTERVAL '1' SECOND) AS wid;
CREATE WINDOW VIEW test_01048.wv ENGINE Memory AS SELECT count(a) AS count FROM test_01048.mt GROUP BY hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) AS wid, b;
CREATE WINDOW VIEW test_01048.wv ENGINE Memory AS SELECT count(a) AS count FROM test_01048.mt GROUP BY hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) AS wid, plus(a, b);
CREATE WINDOW VIEW test_01048.wv ENGINE Memory AS SELECT count(a) AS count, tumbleEnd(wid) as wend FROM test_01048.mt GROUP BY tumble(timestamp, INTERVAL 1 SECOND) as wid;
CREATE WINDOW VIEW test_01048.wv ENGINE Memory AS SELECT count(test_01048.mt.a), count(test_01048.mt_2.b), wid FROM test_01048.mt JOIN test_01048.mt_2 ON test_01048.mt.timestamp = test_01048.mt_2.timestamp GROUP BY hop(test_01048.mt.timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW test_01048.wv ENGINE Memory AS SELECT count(test_01048.mt.a), count(test_01048.mt_2.b), wid FROM test_01048.mt JOIN test_01048.mt_2 ON test_01048.mt.timestamp = test_01048.mt_2.timestamp GROUP BY tumble(test_01048.mt.timestamp, INTERVAL '1' SECOND) AS wid;
CREATE WINDOW VIEW test_01048.wv ENGINE Memory POPULATE AS SELECT count(test_01048.mt.a), count(test_01048.mt_2.b), wid FROM test_01048.mt JOIN test_01048.mt_2 ON test_01048.mt.timestamp = test_01048.mt_2.timestamp GROUP BY hop(test_01048.mt.timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW test_01048.wv ENGINE Memory POPULATE AS SELECT count(test_01048.mt.a), count(test_01048.mt_2.b), wid FROM test_01048.mt JOIN test_01048.mt_2 ON test_01048.mt.timestamp = test_01048.mt_2.timestamp GROUP BY tumble(test_01048.mt.timestamp, INTERVAL '1' SECOND) AS wid;
CREATE WINDOW VIEW window_view_02342 ENGINE=Memory AS SELECT count(a), tumbleStart(wid) AS w_start, tumbleEnd(tumble(now(), INTERVAL '3' SECOND)) AS w_end FROM data_02342 GROUP BY tumble(now(), INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW wv ENGINE Memory AS SELECT count(a), hopStart(wid) AS w_start FROM mt GROUP BY hop(timestamp, INTERVAL '3' SECOND, INTERVAL '5' SECOND) AS wid;
CREATE WINDOW VIEW wv ENGINE Memory AS SELECT count(a), hopStart(wid) AS w_start FROM mt WHERE a != 1 GROUP BY hop(timestamp, INTERVAL '3' SECOND, INTERVAL '5' SECOND) AS wid ORDER BY w_start;
CREATE WINDOW VIEW wv ENGINE Memory AS SELECT count(a), hopStart(wid) AS w_start FROM mt WHERE a != 1 GROUP BY hop(timestamp, INTERVAL '3' SECOND, INTERVAL '5' SECOND) AS wid;
CREATE WINDOW VIEW wv ENGINE Memory AS SELECT count(a), hopStart(wid) AS w_start, hopEnd(hop(now(), INTERVAL '1' SECOND, INTERVAL '3' SECOND)) as w_end FROM mt GROUP BY hop(now(), INTERVAL '1' SECOND, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW wv ENGINE Memory AS SELECT count(a), hopStart(wid) AS w_start, hopEnd(wid) AS w_end FROM mt GROUP BY hop(timestamp, INTERVAL '3' SECOND, INTERVAL '5' SECOND) AS wid;
CREATE WINDOW VIEW wv ENGINE Memory AS SELECT count(a), tumbleStart(tumble(timestamp, INTERVAL '3' SECOND)) AS w_start, tumbleEnd(wid) AS w_end FROM mt GROUP BY tumble(timestamp, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW wv ENGINE Memory AS SELECT count(a), tumbleStart(wid) AS w_start FROM mt GROUP BY tumble(timestamp, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW wv ENGINE Memory AS SELECT count(a), tumbleStart(wid) AS w_start FROM mt WHERE a != 1 GROUP BY tumble(timestamp, INTERVAL '3' SECOND) AS wid ORDER BY w_start;
CREATE WINDOW VIEW wv ENGINE Memory AS SELECT count(a), tumbleStart(wid) AS w_start FROM mt WHERE a != 1 GROUP BY tumble(timestamp, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW wv ENGINE Memory AS SELECT count(a), tumbleStart(wid) AS w_start, tumbleEnd(tumble(now(), INTERVAL '3' SECOND)) AS w_end FROM mt GROUP BY tumble(now(), INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW wv Engine Memory as select count(id), tumbleStart(w_id) as window_start from data group by tumble(timestamp, INTERVAL '10' SECOND) as w_id;
CREATE WINDOW VIEW wv ENGINE Memory AS WITH toDateTime('2018-01-01 00:00:00') AS date_time SELECT count(a), hopStart(wid) AS w_start, hopEnd(wid) AS w_end, date_time FROM mt GROUP BY hop(timestamp, INTERVAL '3' SECOND, INTERVAL '5' SECOND) AS wid;
CREATE WINDOW VIEW wv ENGINE Memory AS WITH toDateTime('2018-01-01 00:00:00') AS date_time SELECT count(a), tumbleStart(wid) AS w_start, tumbleEnd(wid) AS w_end, date_time FROM mt GROUP BY tumble(timestamp, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW wv ENGINE Memory WATERMARK=INTERVAL '1' SECOND AS SELECT count(a), hopStart(wid) AS w_start, hopEnd(wid) AS w_end FROM mt GROUP BY hop(timestamp, INTERVAL '3' SECOND, INTERVAL '5' SECOND) AS wid;
CREATE WINDOW VIEW wv ENGINE Memory WATERMARK=INTERVAL '1' SECOND AS SELECT count(a), tumbleStart(wid) AS w_start, tumbleEnd(wid) AS w_end FROM mt GROUP BY tumble(timestamp, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv ENGINE Memory WATERMARK=ASCENDING AS SELECT count(a) AS count, market, tumbleEnd(wid) AS w_end FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY tumble(timestamp, INTERVAL '5' SECOND) AS wid, market;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY (hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND), b) PRIMARY KEY hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) ENGINE Memory AS SELECT count(a) AS count FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY b, hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY (hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND), plus(a, b)) PRIMARY KEY hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) ENGINE Memory AS SELECT count(a) AS count FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY plus(a, b) as _type, hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY (tumble(timestamp, INTERVAL '1' SECOND), b) PRIMARY KEY tumble(timestamp, INTERVAL '1' SECOND) ENGINE Memory AS SELECT count(a) AS count FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY b, tumble(timestamp, INTERVAL '1' SECOND) AS wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY (tumble(timestamp, INTERVAL '1' SECOND), plus(a, b)) PRIMARY KEY tumble(timestamp, INTERVAL '1' SECOND) ENGINE Memory AS SELECT count(a) AS count FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY plus(a, b) as _type, tumble(timestamp, INTERVAL '1' SECOND) AS wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) ENGINE Memory AS SELECT count(a) AS count, hopEnd(wid) FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) as wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY hop({CLICKHOUSE_DATABASE:Identifier}.mt.timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) ENGINE Memory AS SELECT count({CLICKHOUSE_DATABASE:Identifier}.mt.a), count({CLICKHOUSE_DATABASE:Identifier}.mt_2.b), wid FROM {CLICKHOUSE_DATABASE:Identifier}.mt JOIN {CLICKHOUSE_DATABASE:Identifier}.mt_2 ON {CLICKHOUSE_DATABASE:Identifier}.mt.timestamp = {CLICKHOUSE_DATABASE:Identifier}.mt_2.timestamp GROUP BY hop({CLICKHOUSE_DATABASE:Identifier}.mt.timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY id ENGINE Memory AS SELECT count(a) AS count, b as id FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY id, hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND);
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY id ENGINE Memory AS SELECT count(a) AS count, b as id FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY id, tumble(timestamp, INTERVAL '1' SECOND);
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY tumble(timestamp, INTERVAL '1' SECOND) ENGINE Memory AS SELECT count(a), tumbleEnd(wid) AS count FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY tumble(timestamp, INTERVAL '1' SECOND) as wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY tumble({CLICKHOUSE_DATABASE:Identifier}.mt.timestamp, INTERVAL '1' SECOND) ENGINE Memory AS SELECT count({CLICKHOUSE_DATABASE:Identifier}.mt.a), count({CLICKHOUSE_DATABASE:Identifier}.mt_2.b), wid FROM {CLICKHOUSE_DATABASE:Identifier}.mt JOIN {CLICKHOUSE_DATABASE:Identifier}.mt_2 ON {CLICKHOUSE_DATABASE:Identifier}.mt.timestamp = {CLICKHOUSE_DATABASE:Identifier}.mt_2.timestamp GROUP BY tumble({CLICKHOUSE_DATABASE:Identifier}.mt.timestamp, INTERVAL '1' SECOND) AS wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY wid ENGINE Memory AS SELECT count(a) AS count, hop(timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) AS wid FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY wid ENGINE Memory AS SELECT count(a) AS count, tumble(timestamp, INTERVAL '1' SECOND) AS wid FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY wid ENGINE Memory AS SELECT count({CLICKHOUSE_DATABASE:Identifier}.mt.a), count({CLICKHOUSE_DATABASE:Identifier}.mt_2.b), wid FROM {CLICKHOUSE_DATABASE:Identifier}.mt JOIN {CLICKHOUSE_DATABASE:Identifier}.mt_2 ON {CLICKHOUSE_DATABASE:Identifier}.mt.timestamp = {CLICKHOUSE_DATABASE:Identifier}.mt_2.timestamp GROUP BY hop({CLICKHOUSE_DATABASE:Identifier}.mt.timestamp, INTERVAL '1' SECOND, INTERVAL '3' SECOND) AS wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY wid ENGINE Memory AS SELECT count({CLICKHOUSE_DATABASE:Identifier}.mt.a), count({CLICKHOUSE_DATABASE:Identifier}.mt_2.b), wid FROM {CLICKHOUSE_DATABASE:Identifier}.mt JOIN {CLICKHOUSE_DATABASE:Identifier}.mt_2 ON {CLICKHOUSE_DATABASE:Identifier}.mt.timestamp = {CLICKHOUSE_DATABASE:Identifier}.mt_2.timestamp GROUP BY tumble({CLICKHOUSE_DATABASE:Identifier}.mt.timestamp, INTERVAL '1' SECOND) AS wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY wid PARTITION BY wid ENGINE Memory AS SELECT count(a) AS count, hopEnd(wid) FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY hop(now(), INTERVAL '1' SECOND, INTERVAL '3' SECOND) as wid;
CREATE WINDOW VIEW {CLICKHOUSE_DATABASE:Identifier}.wv INNER ENGINE AggregatingMergeTree ORDER BY wid PARTITION BY wid ENGINE Memory AS SELECT count(a) AS count, tumble(now(), INTERVAL '1' SECOND) AS wid FROM {CLICKHOUSE_DATABASE:Identifier}.mt GROUP BY wid;
DELETE FROM 02416_rocksdb WHERE 1 = 1;
DELETE FROM 02416_rocksdb WHERE value LIKE 'Some%string';
DELETE FROM 02418_test WHERE key <= 2;
DELETE FROM 02577_keepermap_delete_update WHERE 1 = 1;
DELETE FROM 02577_keepermap_delete_update WHERE value LIKE 'Some%string';
DELETE FROM 02581_trips WHERE id IN (SELECT (number*10 + 9)::UInt32 FROM numbers(200000000));
DELETE FROM 02707_keepermap_delete_update WHERE 1 = 1;
DELETE FROM 02707_keepermap_delete_update WHERE value LIKE 'Some%string';
DELETE FROM kekv WHERE a = 1;
DELETE FROM lwd_test WHERE id < 100000;
DELETE FROM lwd_test WHERE id < 200000;
DELETE FROM lwd_test WHERE id < 300000;
DELETE FROM lwd_test WHERE id >= 300000 and id < 400000;
DELETE FROM lwd_test_02521 WHERE id < 25000;
DELETE FROM merge_table_standard_delete WHERE 1;
DELETE FROM merge_table_standard_delete WHERE id = 10;
DELETE FROM merge_table_standard_delete WHERE name IN ('1','2','3','4');
DELETE FROM replicated_table_r1 WHERE 1;
DELETE FROM replicated_table_r1 WHERE id = 10;
DELETE FROM replicated_table_r2 WHERE name IN ('1','2','3','4');
DELETE FROM t1_local ON CLUSTER test_shard_localhost WHERE tc1 = 1;
DELETE FROM t_large WHERE a = 50000;
DELETE FROM t_light WHERE c%5=1;
DELETE FROM t_light WHERE c=4;
DELETE FROM t_light_r1 WHERE c%5=1;
DELETE FROM t_light_r2 WHERE c=4;
DELETE FROM t_light_sync_r1 WHERE c%3=1;
DELETE FROM t_lwd_mutations WHERE id % 10 = 0;
DELETE FROM t_lwd_mutations WHERE id % 10 = 2;
DELETE FROM t_materialize_delete WHERE id % 7 = 3;
DELETE FROM t_materialize_delete WHERE id % 7 = 4;
DELETE FROM t_missed_subcolumns WHERE obj.k1.k3 = 'fee';
DELETE FROM t_mutations_subcolumns WHERE obj.k1.k2 = 'fee';
DELETE FROM t_obj WHERE id = 10;
DELETE FROM t_proj WHERE a < 100;
DELETE FROM t_projections_lwd WHERE a = 2;
DELETE FROM t_sparse_mutation WHERE id % 2 = 0;
DELETE FROM table_02513 WHERE n%10=0;
delete from test where id % 2 = 0 SETTINGS mutations_sync=0;
DELETE FROM test_apply_deleted_mask WHERE id % 2 = 0;
DESC (SELECT * FROM HASH_MV);
desc (select * from system.numbers);
desc (select 1);
DESC alter_test;
DESC check_comments;
desc file (02376_data.arrow);
desc file('02374_data1.jsonl');
desc file('02374_data2.jsonl');
desc file('02841.parquet');
desc file('02892.orc');
desc file('02906.orc');
desc file('data.native.zst');
desc file('data_02318.tsv', 'Template') SETTINGS format_template_row='nonexist', format_template_resultset='nonexist';
desc file('test_02244', 'CSV') settings column_names_for_schema_inference='x,y';
desc file('test_02244', 'JSONCompactEachRow') settings column_names_for_schema_inference='x,y';
desc file('test_02244', 'TSV') settings column_names_for_schema_inference='x,y';
desc file('test_02244', 'Values') settings column_names_for_schema_inference='x,y';
desc file(02384_data.arrow);
desc file(02416_data.json);
desc file(02416_data.jsonColumnsWithMetadata);
desc file(02416_data.jsonCompact);
desc file(02417_data.jsonObjectEachRow);
desc file(02454_data.jsonobjecteachrow);
desc file(basic_types_02735.parquet);
desc file(data_02304.arrow);
desc file(data_02304.orc);
desc file(data_02304.parquet);
desc file(data_02313.avro);
desc file(data_02314.csv) settings input_format_csv_skip_first_lines=5;
desc file(data_02314.tsv) settings input_format_tsv_skip_first_lines=5;
desc file(datetime64_02735.parquet);
desc format('CSV', '-100000000000000000000');
desc format('CSV', '100000000000000000000');
desc format('JSONEachRow', '{"a" : null}, {"a" : 42}') settings input_format_max_bytes_to_read_for_schema_inference=10;
desc format(CSV, '"2020-01-01 00:00:00"');
desc format(CSV, '"2020-01-01 00:00:00"\n"2020-01-01"');
desc format(CSV, '"2020-01-01 00:00:00"\n"Some string"');
desc format(CSV, '"2020-01-01 00:00:00.00000"');
desc format(CSV, '"2020-01-01"');
desc format(CSV, '"42","42.42","True"');
desc format(CSV, '"42","42.42","True"\n"abc","def","ghk"');
desc format(CSV, '"[1, 2]"\n"[3]"');
desc format(CSV, '"[1, 2]"\n"[null]"');
desc format(CSV, '"[1,2]"');
desc format(CSV, '"[123, 123]"');
desc format(CSV, '"[123, 123]"\n"[321.321, 312]"');
desc format(CSV, '"[[\'2020-01-01\', null, \'1234\'], [\'abcd\']]"');
desc format(CSV, '"[[], [null], [1, 2, 3]]"');
desc format(CSV, '"[\'2020-01-01 00:00:00\', \'2020-01-01 00:00:00\']"');
desc format(CSV, '"[\'2020-01-01 00:00:00\', \'2020-01-01\']"\n"[\'2020-01-01\', \'Some string\']"');
desc format(CSV, '"[\'2020-01-01 00:00:00\', \'2020-01-01\']"\n"[\'2020-01-01\']"');
desc format(CSV, '"[\'2020-01-01 00:00:00\', \'Some string\']"');
desc format(CSV, '"[\'2020-01-01 00:00:00\']"\n"[\'2020-01-01\']"');
desc format(CSV, '"[\'2020-01-01\', \'2020-01-01 00:00:00\']"');
desc format(CSV, '"[\'2020-01-01\', \'2020-01-02\']"');
desc format(CSV, '123');
desc format(CSV, '123\n123.123');
desc format(CSV, '\\N') settings schema_inference_hints='x Nullable(UInt32)', column_names_for_schema_inference='x';
desc format(CSV, 'a1 Int32, a2 UInt64, a3 Array(Int32), a4 Array(Array(String))', '1,2,"[1,2,3]","[[\'abc\'], [], [\'d\', \'e\']]"');
desc format(JSON, '{"a" : 10, "b" : "Hello"}');
desc format(JSONCompactEachRow, '[1234], ["String"]') settings input_format_json_try_infer_numbers_from_strings=1;
desc format(JSONCompactEachRow, '[[1, 2]]');
desc format(JSONEachRow, '{"x" : {"a" : [123, 123]}}\n{"x" : {"b" : [321.321, 123]}}');
desc format(JSONEachRow, '{"x" : {"a" : null}}, {"x" : {"b" : 1}}');
desc format(JSONEachRow, '{"x" : {"date1" : "2020-01-01 00:00:00", "date2" : "2020-01-01"}}');
desc format(JSONEachRow, '{"x" : {"k1" : "123", "k2" : "Some string"}}');
desc format(JSONEachRow, '{"x" : {"k1" : "123", "k2" : 123}}');
desc format(JSONEachRow, '{"x" : {"k1" : "123"}}\n{"x" : {"k2" : "Some string"}}');
desc format(JSONEachRow, '{"x" : {"k1" : "123"}}\n{"x" : {"k2" : 123}}');
desc format(JSONEachRow, '{"x" : {"k1" : ["123", "123"], "k2" : ["Some string"]}}');
desc format(JSONEachRow, '{"x" : {"k1" : ["123", "123"], "k2" : [123, 123]}}');
desc format(JSONEachRow, '{"x" : {"k1" : ["123", "123"]}}\n{"x": {"k2" : ["Some string"]}}');
desc format(JSONEachRow, '{"x" : {"k1" : ["123", "123"]}}\n{"x": {"k2" : [123, 123]}}');
desc format(JSONEachRow, '{"x" : {"key" : [42, null]}}');
desc format(JSONEachRow, '{"x" : {"key1" : [["2020-01-01 00:00:00"]], "key2" : [["2020-01-01"]]}}\n{"x" : {"key1" : [["2020-01-01"]], "key2" : [["Some string"]]}}');
desc format(JSONEachRow, '{"x" : {}}') settings schema_inference_hints='x Map(String, String)';
desc format(JSONEachRow, '{"x" : {}}, {"x" : {"a" : 1}}');
desc format(TSV, '122\n1e2');
desc format(TSV, '123');
desc format(TSV, '123\n123.123');
desc format(TSV, '2020-01-01 00:00:00');
desc format(TSV, '2020-01-01 00:00:00.00000');
desc format(TSV, '2020-01-01 00:00:00\n2020-01-01');
desc format(TSV, '2020-01-01 00:00:00\nSome string');
desc format(TSV, '2020-01-01');
desc format(TSV, '[123, 123]');
desc format(TSV, '[123, 123]\n[321.321, 312]');
desc format(TSV, '[\'2020-01-01 00:00:00\', \'2020-01-01 00:00:00\']');
desc format(TSV, '[\'2020-01-01 00:00:00\', \'2020-01-01\']\n[\'2020-01-01\', \'Some string\']');
desc format(TSV, '[\'2020-01-01 00:00:00\', \'2020-01-01\']\n[\'2020-01-01\']');
desc format(TSV, '[\'2020-01-01 00:00:00\', \'Some string\']');
desc format(TSV, '[\'2020-01-01 00:00:00\']\n[\'2020-01-01\']');
desc format(TSV, '[\'2020-01-01\', \'2020-01-01 00:00:00\']');
desc format(TSV, '[\'2020-01-01\', \'2020-01-02\']');
desc format(TSV, '{\'a\' : [123, 123]}');
desc format(TSV, '{\'a\' : [123, 123]}\n{\'b\' : [321, 321]}');
desc format(TSV, '{\'a\' : [123, 123]}\n{\'b\' : [321.321, 123]}');
desc format(TSV, '{\'date1\' : \'2020-01-01 00:00:00\', \'date2\' : \'2020-01-01\'}');
desc format(TSV, '{\'key1\' : [[\'2020-01-01 00:00:00\']], \'key2\' : [[\'2020-01-01\']]}\n{\'key1\' : [[\'2020-01-01\']], \'key2\' : [[\'Some string\']]}');
desc format(Values, '(122), (1e2)');
desc format(Values, '(123)');
desc format(Values, '(123), (123.123)');
desc format(Values, '([123, 123])');
desc format(Values, '([123, 123])\n([321.321, 312])');
desc format(Values, '([\'2020-01-01 00:00:00\', \'2020-01-01 00:00:00\'])');
desc format(Values, '([\'2020-01-01 00:00:00\', \'2020-01-01\'])\n([\'2020-01-01\', \'Some string\'])');
desc format(Values, '([\'2020-01-01 00:00:00\', \'2020-01-01\'])\n([\'2020-01-01\'])');
desc format(Values, '([\'2020-01-01 00:00:00\', \'Some string\'])');
desc format(Values, '([\'2020-01-01 00:00:00\']), ([\'2020-01-01\'])');
desc format(Values, '([\'2020-01-01\', \'2020-01-01 00:00:00\'])');
desc format(Values, '([\'2020-01-01\', \'2020-01-02\'])');
desc format(Values, '(\'2020-01-01 00:00:00.00000\')');
desc format(Values, '(\'2020-01-01 00:00:00\')');
desc format(Values, '(\'2020-01-01 00:00:00\')\n(\'2020-01-01\')');
desc format(Values, '(\'2020-01-01 00:00:00\')\n(\'Some string\')');
desc format(Values, '(\'2020-01-01\')');
desc format(Values, '({\'a\' : [123, 123]}), ({\'b\' : [321, 321]})');
desc format(Values, '({\'a\' : [123, 123]}), ({\'b\' : [321.321, 123]})');
desc format(Values, '({\'date1\' : \'2020-01-01 00:00:00\', \'date2\' : \'2020-01-01\'})');
desc format(Values, '({\'key1\' : [[\'2020-01-01 00:00:00\']], \'key2\' : [[\'2020-01-01\']]})\n({\'key1\' : [[\'2020-01-01\']], \'key2\' : [[\'Some string\']]})');
desc hdfs('hdfs://localhost:12222/test_{1,2,3}.tsv');
desc hdfs('hdfs://localhost:12222/test_{1,2,3}.tsv', 'TSV');
desc hdfs('hdfs://localhost:12222/test_{1,2,3}.tsv', 'TSV', 'c1 UInt32, c2 UInt32, c3 UInt32');
desc hdfs('hdfs://localhost:12222/test_{1,2,3}.tsv', 'TSV', 'c1 UInt32, c2 UInt32, c3 UInt32', 'auto');
desc hdfsCluster('test_cluster_one_shard_three_replicas_localhost', 'hdfs://localhost:12222/test_02458_{1,2}.tsv');
desc hdfsCluster('test_cluster_one_shard_three_replicas_localhost', 'hdfs://localhost:12222/test_02458_{1,2}.tsv', 'TSV');
desc hdfsCluster('test_cluster_two_shards_localhost', 'hdfs://localhost:12222/test_{1,2,3}.tsv');
desc hdfsCluster('test_cluster_two_shards_localhost', 'hdfs://localhost:12222/test_{1,2,3}.tsv', 'TSV');
desc hdfsCluster('test_cluster_two_shards_localhost', 'hdfs://localhost:12222/test_{1,2,3}.tsv', 'TSV', 'c1 UInt32, c2 UInt32, c3 UInt32');
desc hdfsCluster('test_cluster_two_shards_localhost', 'hdfs://localhost:12222/test_{1,2,3}.tsv', 'TSV', 'c1 UInt32, c2 UInt32, c3 UInt32', 'auto');
desc remote('127.0.0.2', currentDatabase(), tab);
desc s3Cluster('test_cluster_one_shard_three_replicas_localhost', 'http://localhost:11111/test/{a,b}.tsv', 'auto');
desc s3Cluster('test_cluster_one_shard_three_replicas_localhost', 'http://localhost:11111/test/{a,b}.tsv', 'test', 'testtest');
desc s3Cluster('test_cluster_one_shard_three_replicas_localhost', 'http://localhost:11111/test/{a,b}.tsv', 'test', 'testtest', 'auto');
desc s3Cluster('test_cluster_one_shard_three_replicas_localhost', 'http://localhost:11111/test/{a,b}.tsv', 'test', 'testtest', 'TSV');
desc tab;
desc table (select 1);
DESC TABLE 02483_substitute_udf;
DESC TABLE add_materialized_column_after;
DESC TABLE alter_00061;
DESC TABLE alter_test;
DESC TABLE cast1;
DESC TABLE cast;
DESC TABLE decimal;
desc table defaulted;
DESC TABLE defaults;
desc table enums;
DESC TABLE mt_00168;
DESC TABLE mt_00168_buffer;
desc table remote('127.0.0.2', currentDatabase(), tab);
DESC TABLE replicated_alter1;
DESC TABLE replicated_alter2;
DESC TABLE t_json_desc SETTINGS describe_extend_object_types = 1;
DESC TABLE t_json_desc;
DESC TABLE t_nested_detach;
desc table tab;
desc table test;
DESC TABLE test;
desc table ttl;
desc test format TSVRaw;
desc test_array_tuple;
desc test_nested;
DESC tuple;
desc url('http://localhost:8888/test/data.tsv?get=parameterHere', auto, 'x UInt32');
desc urlCluster('test_cluster_two_shards_localhost', 'http://localhost:11111/test/{a,b,c}.tsv', 'TSV', 'c1 UInt64, c2 UInt64, c3 UInt64');
desc urlCluster('test_cluster_two_shards_localhost', 'http://localhost:11111/test/{a,b,c}.tsv', 'TSV', 'c1 UInt64, c2 UInt64, c3 UInt64', 'auto');
DESCRIBE (SELECT 'test');
DESCRIBE (SELECT (1, 1));
DESCRIBE (SELECT (SELECT 1 AS a, 2 AS b UNION DISTINCT SELECT 1, 2) AS c, c.*);
DESCRIBE (SELECT (SELECT 1 AS a, 2 AS b UNION DISTINCT SELECT 1, 2) AS c, c.a, c.b);
DESCRIBE (SELECT (SELECT 1 AS a, 2 AS b) AS c, c.*);
DESCRIBE (SELECT (SELECT 1 AS a, 2 AS b) AS c, c.a, c.b);
DESCRIBE (SELECT (SELECT 1 UNION DISTINCT SELECT 1), (SELECT 2 UNION DISTINCT SELECT 2), (SELECT 3 UNION DISTINCT SELECT 3) AS a, (SELECT 4 UNION DISTINCT SELECT 4));
DESCRIBE (SELECT arrayMap(x -> test_table.* EXCEPT value, [1,2,3]) FROM test_table);
DESCRIBE (SELECT arrayMap(x -> x + (test_table.id AS first) + (test_table.id AS second) + id, [1,2,3]) FROM test_table);
DESCRIBE (SELECT arrayMap(x -> x + 1, [1,2,3]));
DESCRIBE (SELECT arrayMap(x -> x + test_table.id + test_table.id + id, [1,2,3]) FROM test_table);
DESCRIBE (SELECT cast(tuple(1), 'Tuple (id UInt64)') AS a, arrayMap(x -> untuple(a) AS untupled_value, [1,2,3]) FROM test_table);
DESCRIBE (SELECT cast(tuple(1), 'Tuple (id UInt64)') AS a, arrayMap(x -> untuple(a), [1,2,3]) FROM test_table);
DESCRIBE (SELECT cast(tuple(1), 'Tuple (id UInt64)') AS compound_value, arrayMap(x -> compound_value.*, [1,2,3]));
DESCRIBE (SELECT cast(tuple(1, 'Value'), 'Tuple (id UInt64, value String)') AS a, a.* EXCEPT id);
DESCRIBE (SELECT cast(tuple(1, 'Value'), 'Tuple (id UInt64, value String)') AS a, a.*);
DESCRIBE (SELECT cast(tuple(1, 'Value'), 'Tuple (id UInt64, value String)') AS compound_value, arrayMap(x -> compound_value.* EXCEPT value, [1,2,3]));
DESCRIBE (SELECT cast(tuple(1, 'Value'), 'Tuple (id UInt64, value String)'));
DESCRIBE (SELECT COLUMNS('d'));
DESCRIBE (SELECT COLUMNS('i'), COLUMNS('v') FROM test_table);
DESCRIBE (SELECT COLUMNS(dummy));
DESCRIBE (SELECT COLUMNS(id) FROM test_table);
DESCRIBE (SELECT COLUMNS(id), COLUMNS(value) FROM test_table);
DESCRIBE (SELECT COLUMNS(id, value) EXCEPT (id) APPLY toString FROM test_table);
DESCRIBE (SELECT COLUMNS(id, value) EXCEPT (id) FROM test_table);
DESCRIBE (SELECT COLUMNS(id, value) EXCEPT id REPLACE (5 AS id, 6 as value) APPLY toString FROM test_table);
DESCRIBE (SELECT COLUMNS(id, value) REPLACE (5 AS id) FROM test_table);
DESCRIBE (SELECT COLUMNS(id, value) REPLACE (5 AS id, 6 as value) FROM test_table);
DESCRIBE (SELECT concat(concat(toString(id), '_'), (value)) FROM test_table);
DESCRIBE (SELECT count() OVER () AS window_function);
DESCRIBE (SELECT count() OVER ());
DESCRIBE (SELECT count() OVER (ORDER BY id WITH FILL FROM ((1 + 1) AS from) TO (6 AS to) STEP ((1 + 1) AS step)) FROM test_table);
DESCRIBE (SELECT count() OVER (ORDER BY id WITH FILL FROM 1 + 1 TO 6 STEP 1 + 1) FROM test_table);
DESCRIBE (SELECT count() OVER (ORDER BY id WITH FILL FROM 1 TO 5 STEP 1) FROM test_table);
DESCRIBE (SELECT count() OVER (ORDER BY toNullable(id) NULLS FIRST) FROM test_table);
DESCRIBE (SELECT count() OVER window_name FROM test_table WINDOW window_name AS (PARTITION BY id));
DESCRIBE (SELECT dummy + dummy);
DESCRIBE (SELECT dummy);
DESCRIBE (SELECT id + length(value) FROM test_table);
DESCRIBE (SELECT id IN (SELECT 1) FROM test_table);
DESCRIBE (SELECT id IN (SELECT id FROM test_table_in) FROM test_table);
DESCRIBE (SELECT id IN test_table_in FROM test_table);
DESCRIBE (SELECT id, t1.id, t1.value, t2.id, t2.value FROM test_table_join_1 AS t1 INNER JOIN test_table_join_2 AS t2 USING (id));
DESCRIBE (SELECT id, t1.id, t1.value, t2.id, t2.value, t3.id, t3.value FROM test_table_join_1 AS t1 INNER JOIN test_table_join_2 AS t2 USING (id) INNER JOIN test_table_join_3 AS t3 USING (id));
DESCRIBE (SELECT id, value FROM test_table);
DESCRIBE (SELECT id, value, t1.id, t1.value, t2.id, t2.value FROM test_table_join_1 AS t1 INNER JOIN test_table_join_2 AS t2 USING (id, value));
DESCRIBE (SELECT id, value, t1.id, t1.value, t2.id, t2.value, t3.id, t3.value FROM test_table_join_1 AS t1 INNER JOIN test_table_join_2 AS t2 USING (id, value) INNER JOIN test_table_join_3 AS t3 USING (id, value));
DESCRIBE (SELECT NULL);
DESCRIBE (SELECT NULL, 1, 'test', [1, 2, 3], [(1, 1), (1, 1)]);
DESCRIBE (SELECT one.dummy);
DESCRIBE (SELECT plus(1 AS a, a AS b), plus(b, b), plus(b, b) AS c, concat('Value' AS d, d) AS e, e);
DESCRIBE (SELECT plus(test_table.id AS a, test_table.id), plus(id, id AS b), plus(b, b), plus(test_table.id, test_table.id) FROM test_table);
DESCRIBE (SELECT system.one.dummy);
DESCRIBE (SELECT t1.*, t2.* FROM test_table_join_1 AS t1 INNER JOIN test_table_join_2 AS t2 ON t1.id = t2.id);
DESCRIBE (SELECT t1.*, t2.*, t3.* FROM test_table_join_1 AS t1 INNER JOIN test_table_join_2 AS t2 ON t1.id = t2.id INNER JOIN test_table_join_3 AS t3 ON t2.id = t3.id);
DESCRIBE (SELECT t1.id, t1.value, t1.value_join_1, t2.id, t2.value, t2.value_join_2 FROM test_table_join_1 AS t1 INNER JOIN test_table_join_2 AS t2 ON t1.id = t2.id);
DESCRIBE (SELECT test.id, test.value FROM test_table AS test);
DESCRIBE (SELECT test_table.* FROM test_table);
DESCRIBE (SELECT test_table.* REPLACE id + (id AS id_alias) AS id, id_alias FROM test_table);
DESCRIBE (SELECT test_table.COLUMNS('i'), test_table.COLUMNS('v') FROM test_table);
DESCRIBE (SELECT test_table.COLUMNS(id) FROM test_table);
DESCRIBE (SELECT test_table.COLUMNS(id), test_table.COLUMNS(value) FROM test_table);
DESCRIBE (SELECT test_table.id AS a, a, test_table.id AS b, b AS c, c FROM test_table);
DESCRIBE (SELECT test_table.id FROM test_table);
DESCRIBE (SELECT test_table.id, test_table.id, id FROM test_table);
DESCRIBE (SELECT test_table.id, test_table.value FROM 02337_db.test_table AS test_table);
DESCRIBE (SELECT test_table.id, test_table.value FROM 02337_db.test_table);
DESCRIBE (SELECT test_table.id, test_table.value FROM test_table);
DESCRIBE (SELECT test_table.value FROM test_table);
DESCRIBE (SELECT test_table_join_1.* APPLY toString, test_table_join_2.* APPLY toString FROM test_table_join_1 AS t1 INNER JOIN test_table_join_2 AS t2 ON t1.id = t2.id);
DESCRIBE (SELECT tuple_value.* APPLY x -> x FROM test_table_compound);
DESCRIBE (SELECT tuple_value.* FROM test_table_compound);
DESCRIBE (SELECT value AS alias_value, alias_value.* APPLY toString FROM test_table);
DESCRIBE (SELECT value AS alias_value, alias_value.* FROM test_table);
DESCRIBE (SELECT value AS alias_value, alias_value.value_0_level_0, alias_value.value_1_level_0 FROM test_table);
DESCRIBE (SELECT value FROM test_table);
DESCRIBE (SELECT value.* APPLY toString FROM test_table);
DESCRIBE (SELECT value.* FROM test_table);
DESCRIBE (SELECT value.value_0_level_0 AS alias_value, alias_value.* APPLY toString FROM test_table);
DESCRIBE (SELECT value.value_0_level_0 AS alias_value, alias_value.* FROM test_table);
DESCRIBE (SELECT value.value_0_level_0 AS alias_value, alias_value.value_0_level_1, alias_value.value_1_level_1 FROM test_table);
DESCRIBE (SELECT value.value_0_level_0 AS value_alias, value_alias.* APPLY toString FROM test_table);
DESCRIBE (SELECT value.value_0_level_0 AS value_alias, value_alias.* FROM test_table);
DESCRIBE (SELECT value.value_0_level_0 AS value_alias, value_alias.value_0_level_1, value_alias.value_1_level_1 FROM test_table);
DESCRIBE (SELECT value.value_0_level_0, value.value_1_level_0 FROM test_table);
DESCRIBE (SELECT value.value_0_level_0.* APPLY toString FROM test_table);
DESCRIBE (SELECT value.value_0_level_0.* FROM test_table);
DESCRIBE (SELECT value.value_0_level_0.value_0_level_1, value.value_0_level_0.value_1_level_1 FROM test_table);
DESCRIBE (WITH test_table_in_cte AS (SELECT id FROM test_table) SELECT id IN (SELECT id FROM test_table_in_cte) FROM test_table);
DESCRIBE (WITH test_table_in_cte AS (SELECT id FROM test_table) SELECT id IN test_table_in_cte FROM test_table);
DESCRIBE (WITH x -> * AS test_lambda SELECT test_lambda(1) AS lambda_value, lambda_value FROM test_table);
DESCRIBE (WITH x -> x + 1 AS test_lambda SELECT test_lambda(1));
DESCRIBE FILESYSTEM CACHE '$CLICHOUSE_TEST_UNIQUE_NAME';
DESCRIBE FILESYSTEM CACHE '$CLICHOUSE_TEST_UNIQUE_NAME_2';
DESCRIBE null();
DESCRIBE remote(default, currentDatabase(), t_describe_options) FORMAT PrettyCompactNoEscapes;
DESCRIBE t_ephemeral_02205_1;
DESCRIBE TABLE 02266_auto_add_nullable;
DESCRIBE TABLE check_query_comment_column;
DESCRIBE TABLE compress_table;
DESCRIBE TABLE data_01646;
DESCRIBE TABLE ignore_auto_increment;
describe table merge;
describe table merge_distributed;
describe table merge_tree;
DESCRIBE TABLE null_00557;
DESCRIBE TABLE null_before;
DESCRIBE TABLE pipe;
DESCRIBE TABLE sqllt.table FORMAT Null;
DESCRIBE TABLE t_desc_subcolumns FORMAT PrettyCompactNoEscapes SETTINGS describe_include_subcolumns = 1;
DESCRIBE TABLE t_desc_subcolumns FORMAT PrettyCompactNoEscapes;
DESCRIBE TABLE t_describe_options FORMAT PrettyCompactNoEscapes;
DESCRIBE TABLE test;
DESCRIBE TABLE test_01532_1;
DESCRIBE TABLE test_01532_2;
DESCRIBE TABLE test_01532_3;
DESCRIBE TABLE test_01532_4;
DESCRIBE TABLE test_alter;
DESCRIBE TABLE test_alter_r1;
DESCRIBE TABLE test_alter_r2;
DESCRIBE TABLE trailing_comma_1;
DESCRIBE TABLE trailing_comma_2;
DESCRIBE TABLE trailing_comma_3;
DESCRIBE test;
DETACH TABLE 02181_test_dictionary;
detach table 02681_undrop_detach sync;
DETACH TABLE adaptive_granularity_alter1;
DETACH TABLE adaptive_granularity_alter2;
drop table if exists order_test1;
DROP NAMED COLLECTION IF EXISTS 02918_json_fuzzer;
DROP PROFILE s1_01294, s2_01294, s3_01294, s4_01294, s5_01294, s6_01294, s7_01294, s8_01294, s9_01294, s10_01294;
DROP PROFILE s1_01294, s2_01294, s3_01294, s4_01294, s5_01294, s6_01294, s7_01294;
DROP PROFILE s1_01294, s2_01294, s3_01294, s4_01294, s5_01294, s6_01294;
DROP PROFILE s1_01294, s2_01294, s3_01294, s4_01294;
DROP QUOTA IF EXISTS q10_01297;
DROP QUOTA IF EXISTS q11_01297;
DROP QUOTA IF EXISTS q12_01297;
DROP QUOTA IF EXISTS q13_01297;
DROP QUOTA IF EXISTS q14_01297;
DROP QUOTA IF EXISTS q15_01297;
DROP QUOTA IF EXISTS q16_01297;
DROP QUOTA IF EXISTS q1_01297;
DROP QUOTA IF EXISTS q2_01297;
DROP QUOTA IF EXISTS q2_01297_renamed;
DROP QUOTA IF EXISTS q3_01297;
DROP QUOTA IF EXISTS q4_01297;
DROP QUOTA IF EXISTS q5_01297;
DROP QUOTA IF EXISTS q6_01297;
DROP QUOTA IF EXISTS q7_01297;
DROP QUOTA IF EXISTS q8_01297;
DROP QUOTA IF EXISTS q9_01297;
DROP QUOTA IF EXISTS sqllt_quota;
DROP QUOTA q1_01297, q2_01297, q3_01297, q4_01297, q5_01297, q6_01297, q7_01297, q8_01297, q9_01297, q10_01297, q11_01297, q12_01297;
DROP QUOTA q1_01297, q2_01297, q3_01297, q4_01297, q5_01297, q6_01297, q7_01297, q8_01297;
DROP QUOTA q1_01297, q2_01297, q3_01297, q4_01297, q5_01297, q6_01297, q7_01297;
DROP QUOTA q1_01297, q2_01297, q3_01297, q4_01297;
DROP QUOTA q1_01297, q2_01297;
DROP QUOTA q1_01297, q2_01297_renamed, q3_01297, q4_01297;
DROP SETTINGS PROFILE 'test_01605';
DROP SETTINGS PROFILE IF EXISTS 02294_profile1, 02294_profile2;
DROP SETTINGS PROFILE IF EXISTS s1_01418, s2_01418;
DROP SETTINGS PROFILE IF EXISTS s2_01294_renamed;
DROP SETTINGS PROFILE IF EXISTS sqllt_settings_profile;
DROP SETTINGS PROFILE s1_01294, s2_01294_renamed, s3_01294;
DROP SETTINGS PROFILE s1_01294;
DROP SETTINGS PROFILE s2_01418;

drop temporary table wups;
EXCHANGE DICTIONARIES 01914_db.dictionary_1 AND 01914_db.dictionary_2;
EXCHANGE DICTIONARIES {new_db_name:Identifier}.{old_dict_name:Identifier} AND {new_db_name:Identifier}.{new_dict_name:Identifier};
EXCHANGE TABLES t1 AND t2;
EXCHANGE TABLES t1 AND t3;
EXCHANGE TABLES t2 AND t2;
EXCHANGE TABLES test_01109_other_atomic.t3 AND test_01109_ordinary.t4;
EXCHANGE TABLES test_01191.dict AND test_01191.t;
EXCHANGE TABLES {new_db_name:Identifier}.{old_tbl_name:Identifier} AND {new_db_name:Identifier}.{new_tbl_name:Identifier};
EXISTS DATABASE db_01048;
EXISTS db_01048.t_01048;
EXISTS DICTIONARY db_01018.dict1;
EXISTS DICTIONARY db_01048.t_01048;
EXISTS DICTIONARY memory_db.dict2;
EXISTS DICTIONARY t_01048;
EXISTS t_01048;
EXISTS TABLE `.inner.tmp_mv2`;
EXISTS TABLE `.inner.tmp_mv3`;
EXISTS TABLE `.inner.tmp_mv4`;
EXISTS TABLE `.inner.tmp_mv`;
EXISTS TABLE aine;
EXISTS TABLE db_01048.t_01048;
EXISTS TEMPORARY TABLE temp_tab;
EXISTS VIEW db_01048.t_01048_2;
EXISTS VIEW db_01048.v_01048;
EXISTS VIEW db_01048.v_not_exist;
EXISTS VIEW db_not_exists.v_not_exist;
EXPLAIN (((((((((((((((((((((((((((((SELECT 1 UNION SELECT 1)))))))))))))))))))))))))))));
EXPLAIN (((((((((((((((SELECT 1 UNION ALL SELECT 1) UNION SELECT 1))))))))))))));
EXPLAIN (SELECT 1 UNION ALL (SELECT 1 UNION ALL (SELECT 1 UNION ALL SELECT 1 UNION SELECT 1))) UNION ALL (((SELECT 1) UNION (SELECT 1 UNION ALL (SELECT 1 UNION ALL (SELECT 1 UNION SELECT 1 ) UNION DISTINCT SELECT 1))));
EXPLAIN (SELECT 1 UNION ALL SELECT 1) UNION ALL SELECT 1;
EXPLAIN (SELECT 1 UNION DISTINCT SELECT 1) UNION DISTINCT SELECT 1;
EXPLAIN actions=0, description=0, header=1 SELECT * FROM ( SELECT 'key2' AS key ) AS s1 JOIN ( SELECT 'key1' AS key, '1' AS value UNION ALL SELECT 'key2' AS key, '1' AS value ) AS s2 USING (key);
EXPLAIN AST ALTER user WITH a;
explain ast create function double AS (n) -> 2*n;
EXPLAIN AST CREATE VIEW numbers_pv AS SELECT * FROM numbers LIMIT {amount:UInt8};
explain ast insert into test format TabSeparated balabala;
explain ast insert into test values balabala;
EXPLAIN AST optimize=0 SELECT countDistinct(number) FROM numbers(0);
EXPLAIN AST optimize=1 SELECT * FROM numbers(0);
EXPLAIN AST optimize=1 SELECT countDistinct(number) FROM numbers(0);
EXPLAIN AST SELECT 'x' IS NOT DISTINCT FROM 'x' || 'a';
EXPLAIN AST SELECT - 1 IS NOT DISTINCT FROM 1 ;
EXPLAIN AST SELECT 1 <=> 1 == 1;
EXPLAIN AST SELECT 1 == 1 <=> 1;
EXPLAIN AST SELECT 1 IS NOT DISTINCT FROM 1 + 1;
EXPLAIN AST SELECT 1 IS NOT DISTINCT FROM 1 :: integer;
EXPLAIN AST SELECT a * b IS NULL, a * b IS NOT NULL;
EXPLAIN AST SELECT false IS NOT DISTINCT FROM true IN (true, false);
EXPLAIN AST SELECT false IS NOT DISTINCT FROM true OR true;
EXPLAIN AST SELECT NOT 1 IS NOT DISTINCT FROM 1;
EXPLAIN AST SELECT NULL IS NULL IS NOT DISTINCT FROM NULL;
EXPLAIN AST SELECT true IS NOT DISTINCT FROM 'x' LIKE 'a';
explain ast select tuple(a) -> f(a);
explain ast select tupleElement((255, 1), 1);
explain ast select tupleElement(255, 100);
explain ast;
EXPLAIN description = 0 SELECT day AS s FROM test_table ORDER BY s LIMIT 1 SETTINGS optimize_read_in_order = 0;
EXPLAIN description = 0 SELECT day AS s FROM test_table ORDER BY s LIMIT 1 SETTINGS optimize_read_in_order = 1;
EXPLAIN description = 0 SELECT day, count() AS s FROM test_table GROUP BY day SETTINGS optimize_aggregation_in_order = 0;
EXPLAIN description = 0 SELECT day, count() AS s FROM test_table GROUP BY day SETTINGS optimize_aggregation_in_order = 1;
EXPLAIN description = 0 SELECT toDate(timestamp) AS s FROM test_table ORDER BY toDate(timestamp) LIMIT 1 SETTINGS optimize_read_in_order = 1;
EXPLAIN description = 0 SELECT toDate(timestamp), count() AS s FROM test_table GROUP BY toDate(timestamp) SETTINGS optimize_aggregation_in_order = 1;
explain description=0 select * from remote('127.{1,2}', view(select * from numbers(1e6))) order by number limit 10 settings distributed_push_down_limit=1;
EXPLAIN ESTIMATE SELECT 1 IN (SELECT joinGet(`02843_join`, 'value', materialize(1)));
explain estimate select DISTINCT _partition_id from weird_partitions_02245 where d >= '2021-12-31 00:00:00' and d < '2022-01-01 00:00:00';
explain estimate select DISTINCT _partition_id from weird_partitions_02245 where d >= '2022-01-01 00:00:00' and d1 >= '2021-12-31 00:00:00' and d1 < '2020-01-01 00:00:00';
explain estimate select DISTINCT _partition_id from weird_partitions_02245 where d >= '2022-01-01 00:00:00' and d1 >= '2021-12-31 00:00:00' and d1 < '2022-01-01 00:00:00';
explain estimate select DISTINCT _partition_id from weird_partitions_02245 where d1 >= '2021-12-31 00:00:00' and d1 < '2022-01-01 00:00:00';
EXPLAIN ESTIMATE SELECT 0 = 1048577, NULL, groupBitmapOr(bitmapBuild([toInt32(65537)])) FROM cluster(test_cluster_two_shards) WHERE NULL = 1048575;
EXPLAIN ESTIMATE SELECT any(s) FROM (SELECT '' AS s) AS t1 JOIN (SELECT '' AS s GROUP BY connection_id()) AS t2 USING (s);
EXPLAIN ESTIMATE SELECT count() FROM partition_by_ignore WHERE ts BETWEEN toDateTime('2022-08-07 00:00:00') AND toDateTime('2022-08-10 00:00:00') FORMAT CSV;
EXPLAIN ESTIMATE SELECT count() FROM partition_by_ignore WHERE ts_2 BETWEEN toDateTime('2022-08-07 00:00:00') AND toDateTime('2022-08-10 00:00:00') FORMAT CSV;
explain header = 1 select 1 as x;
EXPLAIN header = 1, actions = 1 SELECT id, value FROM test_table PREWHERE id = 5 settings allow_experimental_analyzer=0;
EXPLAIN header = 1, actions = 1 SELECT id, value FROM test_table PREWHERE id = 5 settings allow_experimental_analyzer=1;
EXPLAIN header = 1, actions = 1 SELECT lhs.id, lhs.value_1, rhs.id, rhs.value_1 FROM test_table_1 AS lhs ASOF JOIN test_table_2 AS rhs ON lhs.id = rhs.id AND lhs.value_2 < rhs.value_2;
EXPLAIN header = 1, actions = 1 SELECT lhs.id, lhs.value_1, rhs.id, rhs.value_1 FROM test_table_1 AS lhs INNER JOIN test_table_2 AS rhs ON lhs.id = rhs.id;
EXPLAIN header = 1, actions = 1 SELECT number FROM (SELECT number FROM numbers(2) ORDER BY ignore(2)) WHERE ignore(2);
EXPLAIN header = 1, actions = 1 SELECT t1.id, t1.value, t2.value FROM test_table AS t1 INNER JOIN test_table_join AS t2 ON t1.id = t2.id WHERE t1.id = 0;
explain indexes = 1 select * from test1 where a > 10 settings allow_experimental_analyzer = 0;
explain indexes = 1 select * from test1 where a > 10 settings allow_experimental_analyzer = 1;
explain indexes = 1 select * from test2 where a2 > 15 settings allow_experimental_analyzer = 0;
explain indexes = 1 select * from test2 where a2 > 15 settings allow_experimental_analyzer = 1;
EXPLAIN indexes = 1 SELECT * FROM test_skip_idx WHERE id < 2;
EXPLAIN indexes = 1 SELECT * FROM test_skip_idx WHERE id < 3;
EXPLAIN indexes = 1 SELECT id FROM test_table WHERE id <= 10 AND value IN (SELECT '5');
EXPLAIN indexes = 1 SELECT id FROM test_table WHERE id <= 10 AND value IN (SELECT 5);
EXPLAIN indexes = 1 SELECT id FROM test_table WHERE id <= 10 AND value IN (SELECT toString(number) FROM numbers(5));
EXPLAIN indexes = 1 SELECT id FROM test_table WHERE id <= 10 AND value IN (SELECT toUInt8(number) FROM numbers(5));
EXPLAIN indexes = 1, description = 0 SELECT * FROM tab WHERE has(foo, 'b');
EXPLAIN indexes=1 SELECT id, delete_time FROM t1 CROSS JOIN (   SELECT delete_time   FROM t2 ) AS d WHERE create_time < delete_time AND id = 101 SETTINGS allow_experimental_analyzer=0;
EXPLAIN indexes=1 SELECT id, delete_time FROM t1 CROSS JOIN (   SELECT delete_time   FROM t2 ) AS d WHERE create_time < delete_time AND id = 101 SETTINGS allow_experimental_analyzer=1;
EXPLAIN indexes=1 WITH (0.0, 2.0) as reference_vec SELECT id, vec, cosineDistance(vec, reference_vec) FROM tab_annoy ORDER BY cosineDistance(vec, reference_vec) LIMIT 3 SETTINGS max_limit_for_ann_queries=2;
EXPLAIN indexes=1 WITH (0.0, 2.0) as reference_vec SELECT id, vec, cosineDistance(vec, reference_vec) FROM tab_usearch ORDER BY cosineDistance(vec, reference_vec) LIMIT 3 SETTINGS max_limit_for_ann_queries=2;
EXPLAIN indexes=1 WITH [0.0, 2.0] AS reference_vec SELECT id, vec, L2Distance(vec, reference_vec) FROM tab_annoy ORDER BY L2Distance(vec, reference_vec) LIMIT 3;
EXPLAIN indexes=1 WITH [0.0, 2.0] AS reference_vec SELECT id, vec, L2Distance(vec, reference_vec) FROM tab_annoy WHERE L2Distance(vec, reference_vec) < 1.0 LIMIT 3;
EXPLAIN indexes=1 WITH [0.0, 2.0] AS reference_vec SELECT id, vec, L2Distance(vec, reference_vec) FROM tab_usearch ORDER BY L2Distance(vec, reference_vec) LIMIT 3;
EXPLAIN indexes=1 WITH [0.0, 2.0] AS reference_vec SELECT id, vec, L2Distance(vec, reference_vec) FROM tab_usearch WHERE L2Distance(vec, reference_vec) < 1.0 LIMIT 3;
EXPLAIN PIPELINE graph = 1, compact = 1 SELECT * FROM merge1 FORMAT Null SETTINGS allow_experimental_analyzer=1;
EXPLAIN PIPELINE graph = 1, compact = 1 SELECT * FROM merge1 FORMAT Null;
explain pipeline graph=1 select max(ID) from t1 FORMAT Null;
explain pipeline graph=1 select min(ID) from t1 FORMAT Null;
explain pipeline graph=1 select sum(1) from t1 FORMAT Null;
EXPLAIN PIPELINE SELECT * FROM (   SELECT     day_,     if(type_1 = '', 'all', type_1) AS type_1   FROM   (     SELECT       day_,       type_1     FROM test_grouping_sets_predicate     GROUP BY       GROUPING SETS (         (day_, type_1),         (day_))   ) AS t ) WHERE day_ = '2023-01-05' settings allow_experimental_analyzer=0;
EXPLAIN PIPELINE SELECT * FROM (   SELECT     day_,     if(type_1 = '', 'all', type_1) AS type_1   FROM   (     SELECT       day_,       type_1     FROM test_grouping_sets_predicate     WHERE day_ = '2023-01-05'     GROUP BY       GROUPING SETS (         (day_, type_1),         (day_))   ) AS t ) WHERE type_1 = 'all' settings allow_experimental_analyzer=0;
EXPLAIN PIPELINE SELECT * FROM (   SELECT * FROM system.numbers LIMIT 10 ) t1 ALL LEFT JOIN (   SELECT * FROM system.numbers LIMIT 10 ) t2 USING number SETTINGS max_threads=16;
explain pipeline select * from (select * from numbers_mt(1e8) group by number) group by number;
explain pipeline select * from (select * from numbers_mt(1e8) group by number) order by number;
EXPLAIN PIPELINE SELECT * FROM data FINAL WHERE v1 >= now() - INTERVAL 180 DAY SETTINGS max_threads=2, max_final_threads=2, force_data_skipping_indices='v1_index', use_skip_indexes_if_final=0 FORMAT LineAsString;
EXPLAIN PIPELINE SELECT * FROM t_read_in_order WHERE date = '2020-10-11' ORDER BY i, v LIMIT 5 settings allow_experimental_analyzer=0;
EXPLAIN PIPELINE SELECT * FROM t_read_in_order WHERE date = '2020-10-11' ORDER BY i, v LIMIT 5 settings allow_experimental_analyzer=1;
explain pipeline select * from test final SETTINGS enable_vertical_final = 0;
EXPLAIN PIPELINE SELECT 1 + number from system.numbers LIMIT 1 SETTINGS use_query_cache = true;
explain pipeline select a from remote(test_cluster_two_shards, currentDatabase(), dist_t) group by a;
EXPLAIN PIPELINE SELECT a FROM t GROUP BY a FORMAT PrettySpace SETTINGS optimize_aggregation_in_order = 1;
explain pipeline select a from t1 group by a;
explain pipeline select a from t2 group by a;
explain pipeline select a from t3 group by a;
explain pipeline select a from t4 group by a settings read_in_order_two_level_merge_threshold = 1e12;
explain pipeline select a from t5 group by a settings read_in_order_two_level_merge_threshold = 1e12;
explain pipeline select a from t6 group by a settings read_in_order_two_level_merge_threshold = 1e12;
EXPLAIN PIPELINE SELECT toStartOfDay(dt) as date, d FROM t_read_in_order ORDER BY date, round(d) LIMIT 5;
EXPLAIN PIPELINE SELECT toStartOfMonth(date) as d, i FROM t_read_in_order ORDER BY d DESC, -i LIMIT 5;
EXPLAIN PIPELINE SELECT toStartOfMonth(date) as d, i FROM t_read_in_order ORDER BY d, -i LIMIT 5;
EXPLAIN PIPELINE SELECT toStartOfMonth(date) as d, i FROM t_read_in_order ORDER BY d, i LIMIT 5;
EXPLAIN PLAN header = 1 SELECT a.a2, d.d2 FROM a JOIN b USING (k) JOIN c USING (k) JOIN d USING (k) ;
EXPLAIN PLAN header = 1 SELECT b.bx FROM a JOIN (SELECT b1, b2 || 'x' AS bx FROM b ) AS b ON b.b1 = a.a1 JOIN c ON c.c1 = b.b1 JOIN (SELECT number AS d1 from numbers(10)) AS d ON d.d1 = c.c1 WHERE c.c2 != '' ORDER BY a.a2 ;
EXPLAIN PLAN SELECT * FROM test_order_by ORDER BY timestamp LIMIT 10;
EXPLAIN PLAN SELECT * FROM test_order_by ORDER BY toDate(timestamp) LIMIT 10;
EXPLAIN PLAN SELECT * FROM test_order_by ORDER BY toDate(timestamp), timestamp LIMIT 10;
EXPLAIN PLAN SELECT 1 + number from system.numbers LIMIT 1 SETTINGS use_query_cache = true;
EXPLAIN QUERY TREE (SELECT sum(if((number % 2) == 0, 0, 1)) FROM numbers(10));
EXPLAIN QUERY TREE (SELECT sum(if((number % 2) == 0, 1, 0)) FROM numbers(10));
EXPLAIN QUERY TREE (SELECT sumIf(1, (number % 2) == 0) FROM numbers(10));
EXPLAIN QUERY TREE dump_ast = 1 SELECT * FROM mysql(   '127.0.0.1:9004', currentDatabase(), foo, 'default', '',   SETTINGS connection_wait_timeout = 123, connect_timeout = 40123002, read_write_timeout = 40123001, connection_pool_size = 3 );
EXPLAIN QUERY TREE run_passes = 0 SELECT 1;
EXPLAIN QUERY TREE run_passes = 0 SELECT arrayMap(x -> x + id, [1, 2, 3]) FROM test_table;
EXPLAIN QUERY TREE run_passes = 0 SELECT id, value FROM test_table;
EXPLAIN QUERY TREE run_passes = 0 WITH x -> x + 1 AS lambda SELECT lambda(id) FROM test_table;
EXPLAIN QUERY TREE run_passes = 1 select arrayExists(x -> 5 = x , materialize(range(10))) from numbers(10);
EXPLAIN QUERY TREE run_passes = 1 select arrayExists(x -> x = 5 , materialize(range(10))) from numbers(10);
EXPLAIN QUERY TREE run_passes = 1 SELECT arrayMap(x -> x + 1, [1, 2, 3]) FROM test_table;
EXPLAIN QUERY TREE run_passes = 1 SELECT avg(b) * 3, sum(b) + 1 + count(b), count(b) * count(b) FROM (SELECT b FROM fuse_tbl);
EXPLAIN QUERY TREE run_passes = 1 select avg(if(number % 2, null, number)) from numbers(100);
EXPLAIN QUERY TREE run_passes = 1 select avg(if(number % 2, number, null)) from numbers(100);
EXPLAIN QUERY TREE run_passes = 1 SELECT CONCAT(number > 5 ? 'censor.net' : 'google', '1') FROM system.numbers LIMIT 10;
EXPLAIN QUERY TREE run_passes = 1 SELECT CONCAT(transform(number, [2, 4, 6], ['google', 'censor.net', 'yahoo'], 'other'), '1') FROM system.numbers LIMIT 10;
EXPLAIN QUERY TREE run_passes = 1 SELECT id, value FROM test_table;
explain query tree select * from (select * from bug where k=1 or k=2 or k=3) where (s=21 or s=22 or s=23) SETTINGS allow_experimental_analyzer = 1;
EXPLAIN QUERY TREE SELECT * FROM 02668_logical_optimizer WHERE a <> 1 AND 1 <> a;
EXPLAIN QUERY TREE SELECT * FROM 02668_logical_optimizer WHERE a <> 1 AND 3 <> a AND 1 <> a;
EXPLAIN QUERY TREE SELECT * FROM 02668_logical_optimizer WHERE a = 1 AND 2 = a;
EXPLAIN QUERY TREE SELECT * FROM 02668_logical_optimizer WHERE a = 1 OR 1 = a;
EXPLAIN QUERY TREE SELECT * FROM 02668_logical_optimizer WHERE a = 1 OR 3 = a OR 1 = a;
EXPLAIN QUERY TREE SELECT grouping(id), grouping(value) FROM test_table GROUP BY CUBE (id, value);
EXPLAIN QUERY TREE SELECT grouping(id), grouping(value) FROM test_table GROUP BY GROUPING SETS ((id), (value));
EXPLAIN SELECT 1 UNION (SELECT 1 UNION ALL SELECT 1);
EXPLAIN SELECT 1 UNION ALL SELECT 1 UNION ALL SELECT 1;
EXPLAIN SELECT 1 UNION DISTINCT (SELECT 1 UNION SELECT 1);
EXPLAIN SELECT 1 UNION SELECT 1 UNION DISTINCT SELECT 1;
EXPLAIN SELECT count() FROM t_skip_index_in WHERE c IN (SELECT throwIf(1)) SETTINGS use_skip_indexes = 1;
EXPLAIN SYNTAX (((((((((((((((SELECT 1 UNION DISTINCT SELECT 1))) UNION DISTINCT SELECT 1)))) UNION ALL SELECT 1))))))));
EXPLAIN SYNTAX (((((((((((((((SELECT 1)))))))))))))));
EXPLAIN SYNTAX CREATE TABLE t (x varchar(255) COLLATE binary NOT NULL) ENGINE=Memory;
EXPLAIN SYNTAX CREATE TABLE t (x varchar(255) COLLATE NOT NULL) ENGINE=Memory;
EXPLAIN SYNTAX INSERT INTO test FROM INFILE 'data.file' WATCH view;
EXPLAIN SYNTAX SELECT '2010-10-10'::Date AS c;
EXPLAIN SYNTAX SELECT '2010-10-10'::DateTime('UTC') AS c;
EXPLAIN SYNTAX SELECT 'abc'::FixedString(3) AS c;
EXPLAIN SYNTAX SELECT (0 + 1 + 2 + 3 + 4)::Date AS c;
EXPLAIN SYNTAX SELECT (0.1, 0.2)::Tuple(Decimal(75, 70), Decimal(75, 70));
EXPLAIN SYNTAX SELECT (0.1::Decimal(4, 4) * 5)::Float64 AS c;
EXPLAIN SYNTAX SELECT [1,2,3]::Array(UInt64)[[number, number]::Array(UInt8)[number]::UInt64]::UInt8 from numbers(3);
EXPLAIN SYNTAX WITH 1, 2 SELECT 1;
explain syntax with 5 as q1, x as (select number + 100 as b, number as a from numbers(10) where number > q1) select * from x;
EXPLAIN SYNTAX WITH [3,4,5] AS x SELECT x[1]::Int32;
explain syntax with it as ( select * from numbers(1) ) select it.number, i.number from it as i;
EXPLAIN SYNTAX WITH tuple(3,4,5) AS x SELECT x.1::Int32;
OPTIMIZE TABLE merge_tree_deduplication FINAL;
OPTIMIZE TABLE 02725_memory_for_merges FINAL;
OPTIMIZE TABLE adaptive_granularity_alter FINAL;
OPTIMIZE TABLE adaptive_granularity_alter1 FINAL;
OPTIMIZE TABLE adaptive_table FINAL;
OPTIMIZE TABLE agg_func_col;
OPTIMIZE TABLE aggregating_00191;
OPTIMIZE TABLE clear_column1 PARTITION '200002';
OPTIMIZE TABLE collapsing PARTITION tuple() FINAL;
OPTIMIZE TABLE collapsing_suspicious_granularity FINAL;
OPTIMIZE TABLE collapsing_table FINAL;
OPTIMIZE TABLE column_size_bug;
OPTIMIZE TABLE columns_with_multiple_streams FINAL;
OPTIMIZE TABLE columns_with_multiple_streams_bad_case FINAL;
OPTIMIZE TABLE compression_codec FINAL;
OPTIMIZE TABLE compression_codec_replicated1 FINAL;
optimize table data final;
OPTIMIZE TABLE data_01285 FINAL;
optimize table z final;
OPTIMIZE TABLE zero_rows_per_granule FINAL;
OPTIMIZE TABLE zero_rows_per_granule2 FINAL;
print '';
print 'ipv4_is_private(strcat(\'192.\',\'168.\',\'1.\',\'1\',\'/24\'))';
print 456;
print a = 4 | extend a = 5;
print array_concat(dynamic([1,2,3]),dynamic([4,5,6]));
print array_rotate_left(dynamic([1,2,3,4,5]), 2);
print array_rotate_left(dynamic([1,2,3,4,5]), 5);
print array_rotate_left(dynamic([1,2,3,4,5]), 7);
print array_rotate_left(dynamic([]), -500);
print array_rotate_left(dynamic([]), 0);
print array_rotate_left(dynamic([]), 500);
print array_rotate_right(dynamic([1,2,3,4,5]), -2);
print array_rotate_right(dynamic([1,2,3,4,5]), -5);
print array_rotate_right(dynamic([1,2,3,4,5]), -7);
print base64_encode_fromguid(guid('ae3133f2-6e22-49ae-b06a-16e6a9b212eb'));
print base64_encode_tostring('');
print base64_encode_tostring('Kusto1');
print bin(16d, 7d);
print bin(4.5, 1);
print bin(datetime(1970-05-11 13:45:07), 1d);
print bin(datetime(1970-05-11 13:45:07.345623), 1ms);
print double('4.2');
print dynamic(1);
print dynamic(['a', "b", 'c']);
print dynamic([1,2,3]);
print dynamic([[1], [2], [3]]);
print dynamic(timespan(1d));
print endofday(datetime(2017-01-01 10:10:17));
print endofday(datetime(2017-01-01 10:10:17), -1);
print endofday(datetime(2017-01-01 10:10:17), 1);
print endofmonth(datetime(2017-01-01 10:10:17));
print endofmonth(datetime(2017-01-01 10:10:17), -1);
print endofmonth(datetime(2017-01-01 10:10:17), 1);
print endofmonth(datetime(2022-09-23));
print endofweek(datetime(2017-01-01 10:10:17));
print endofweek(datetime(2017-01-01 10:10:17), -1);
print endofweek(datetime(2017-01-01 10:10:17), 1);
print endofyear(datetime(2017-01-01 10:10:17));
print endofyear(datetime(2017-01-01 10:10:17), -1);
print endofyear(datetime(2017-01-01 10:10:17), 1);
print extract("x=([0-9.]+)", 1, "hello x=45.6|wo" , typeof(bool));
print extract("x=([0-9.]+)", 1, "hello x=45.6|wo" , typeof(date));
print extract("x=([0-9.]+)", 1, "hello x=45.6|wo" , typeof(decimal));
print extract("x=([0-9.]+)", 1, "hello x=45.6|wo" , typeof(guid));
print extract("x=([0-9.]+)", 1, "hello x=45.6|wo" , typeof(int));
print extract("x=([0-9.]+)", 1, "hello x=45.6|wo" , typeof(long));
print extract("x=([0-9.]+)", 1, "hello x=45.6|wo" , typeof(real));
print extract('(\\b[A-Z]+\\b).+(\\b\\d+)', 0, 'The price of PINEAPPLE ice cream is 20');
print extract('(\\b[A-Z]+\\b).+(\\b\\d+)', 1, 'The price of PINEAPPLE ice cream is 20');
print extract('(\\b[A-Z]+\\b).+(\\b\\d+)', 2, 'The price of PINEAPPLE ice cream is 20');
print extract('(\\b[A-Z]+\\b).+(\\b\\d+)', 2, 'The price of PINEAPPLE ice cream is 20', typeof(real));
print extract('(\\b[A-Z]+\\b).+(\\b\\d+)', 3, 'The price of PINEAPPLE ice cream is 20');
print extract_json('$.age', '{"firstName":"John","lastName":"doe","age":26,"address":{"streetAddress":"naist street","city":"Nara","postalCode":"630-0192"},"phoneNumbers":[{"type":"iPhone","number":"0123-4567-8888"},{"type":"home","number":"0123-4567-8910"}]}');
print extract_json('$.age', '{"firstName":"John","lastName":"doe","age":26,"address":{"streetAddress":"naist street","city":"Nara","postalCode":"630-0192"},"phoneNumbers":[{"type":"iPhone","number":"0123-4567-8888"},{"type":"home","number":"0123-4567-8910"}]}', typeof(guid));
print extract_json('$.age', '{"firstName":"John","lastName":"doe","age":26,"address":{"streetAddress":"naist street","city":"Nara","postalCode":"630-0192"},"phoneNumbers":[{"type":"iPhone","number":"0123-4567-8888"},{"type":"home","number":"0123-4567-8910"}]}', typeof(int));
print extract_json('$.age', '{"firstName":"John","lastName":"doe","age":26,"address":{"streetAddress":"naist street","city":"Nara","postalCode":"630-0192"},"phoneNumbers":[{"type":"iPhone","number":"0123-4567-8888"},{"type":"home","number":"0123-4567-8910"}]}', typeof(long));
print extract_json('$.phoneNumbers[0].type', '');
print extract_json('$.phoneNumbers[0].type', '{"firstName":"John","lastName":"doe","age":26,"address":{"streetAddress":"naist street","city":"Nara","postalCode":"630-0192"},"phoneNumbers":[{"type":"iPhone","number":"0123-4567-8888"},{"type":"home","number":"0123-4567-8910"}]}', typeof(int));
print extract_json('$.phoneNumbers[0].type', '{"firstName":"John","lastName":"doe","age":26,"address":{"streetAddress":"naist street","city":"Nara","postalCode":"630-0192"},"phoneNumbers":[{"type":"iPhone","number":"0123-4567-8888"},{"type":"home","number":"0123-4567-8910"}]}', typeof(string));
print extract_json('', '');
print extractjson('$.firstName', '{"firstName":"John","lastName":"doe","age":26,"address":{"streetAddress":"naist street","city":"Nara","postalCode":"630-0192"},"phoneNumbers":[{"type":"iPhone","number":"0123-4567-8888"},{"type":"home","number":"0123-4567-8910"}]}');
print format_datetime(datetime(2015-12-14 02:03:04.12345), 'y-M-d h:m:s.fffffff');
print format_ipv4('192.168.1.1', 32);
print format_ipv4('192.168.1.1/24', -1) == '';
print format_ipv4('192.168.1.1/24', 32);
print format_ipv4('192.168.1.255', 24);
print format_ipv4('abc', 24) == '';
print format_ipv4(3232236031, 24);
print format_ipv4(strcat('127.0', '.0.', '1', '/32'), 12 + 12);
print format_ipv4_mask('192.168.1.1', 24);
print format_ipv4_mask('192.168.1.1', 32);
print format_ipv4_mask('192.168.1.1/24', -1) == '';
print format_ipv4_mask('192.168.1.1/24', 32);
print format_ipv4_mask('192.168.1.255', 24);
print format_ipv4_mask('abc', 24) == '';
print format_ipv4_mask(3232236031, 24);
print format_ipv4_mask(strcat('127.0', '.0.', '1', '/32'), 12 + 12);
print format_timespan(time('14.02:03:04.12345'), 'h:m:s.fffffff');
print getmonth(datetime(2015-10-12));
print getyear(datetime(2015-10-12));
print getyear(now(-2d))>1900;
print guid(null);
print has_any_index('this is an example', dynamic(['this', 'example'])), has_any_index("this is an example", dynamic(['not', 'example'])), has_any_index("this is an example", dynamic(['not', 'found'])), has_any_index("this is an example", dynamic([]));
print hourofday(datetime(2015-12-31 23:59:59.9));
print int('4');
print int(123);
print int(null);
print ipv4_compare('127.0.0.1', '127.0.0.1');
print ipv4_compare('192.168.1.1', '192.168.1.0', 31);
print ipv4_compare('192.168.1.1', '192.168.1.255');
print ipv4_compare('192.168.1.1', '192.168.1.255', 24);
print ipv4_compare('192.168.1.1', '192.168.1.255/24');
print ipv4_compare('192.168.1.1/24', '192.168.1.255');
print ipv4_compare('192.168.1.1/24', '192.168.1.255', 31);
print ipv4_compare('192.168.1.1/24', '192.168.1.255/24');
print ipv4_compare('192.168.1.1/30', '192.168.1.255/24');
print ipv4_compare('192.168.1.255', '192.168.1.1');
print ipv4_is_in_range('127.0.0.1', '127.0.0.1');
print ipv4_is_in_range('192.168.1.1', '192.168.2.1/24');
print ipv4_is_in_range('192.168.1.6', '192.168.1.1/24');
print ipv4_is_in_range(strcat('192.','168.', '1.1'), '192.168.2.1/24');
print ipv4_is_match('127.0.0.1', '127.0.0.1');
print ipv4_is_match('192.168.1.1', '192.168.1.255');
print ipv4_is_match('192.168.1.1', '192.168.1.255', 24);
print ipv4_is_match('192.168.1.1/24', '192.168.1.255/24');
print ipv4_is_match('abc', 'dev', 24);
print ipv4_is_private('10.1.2.3');
print ipv4_is_private('127.0.0.1');
print ipv4_is_private('192.168.1.1/24');
print ipv4_is_private('abc');
print ipv4_is_private(strcat('192.','168.','1.','1','/24'));
print ipv4_netmask_suffix('127.0.0.1/16');
print ipv4_netmask_suffix('192.168.1.1');
print ipv4_netmask_suffix('192.168.1.1/24');
print ipv4_netmask_suffix('abc');
print ipv4_netmask_suffix(strcat('127.', '0.', '0.1/16'));
print ipv6_is_match('192.168.1.1',  '192.168.1.1');
print ipv6_is_match('192.168.1.1/24', '192.168.1.255/24') == true;
print ipv6_is_match('::ffff:7f00:1', '127.0.0.1') == true;
print ipv6_is_match('fe80::85d:e82c:9446:7994', 'fe80::85d:e82c:9446:7995') == false;
print ipv6_is_match('fe80::85d:e82c:9446:7994', 'fe80::85d:e82c:9446:7995', 127) == true;
print ipv6_is_match('fe80::85d:e82c:9446:7994/127', 'fe80::85d:e82c:9446:7995/127') == true;
print isnan(4);
print isnan(4.2);
print isnan(double(nan));
print isnan(dynamic(null));
print isnull(null);
print jaccard_index(dynamic(['a', 's', 'd']), dynamic(['f', 'd', 's', 'a']));
print jaccard_index(dynamic(['Chewbacca', 'Darth Vader', 'Han Solo']), dynamic(['Darth Sidious', 'Darth Vader']));
print jaccard_index(dynamic([1, 1, 2, 2, 3, 3]), dynamic([1, 2, 3, 4, 4, 4]));
print jaccard_index(dynamic([1, 2, 3]), dynamic([4, 5, 6, 7]));
print jaccard_index(dynamic([1, 2, 3]), dynamic([]));
print jaccard_index(dynamic([]), dynamic([1, 2, 3, 4]));
print jaccard_index(dynamic([]), dynamic([]));
print long(-1);
print long(0xff);
print long(123);
print long(null);
print make_datetime(2017,10,01,12,10) == datetime(2017-10-01 12:10:00);
print monthofyear(datetime(2015-12-31));
print pack_array();
print pack_array(strcat('a', 'b'), format_ipv4(42), tostring(4.2));
print parse_command_line(55, 'windows');
print parse_command_line(strrep(' ', 6), 'windows');
print parse_csv('');
print parse_csv(65);
print parse_ipv4('127.0.0.1');
print parse_ipv4('192.1.168.1') < parse_ipv4('192.1.168.2');
print parse_ipv4(arrayStringConcat(['127', '0', '0', '1'], '.'));
print parse_ipv4_mask('127.0.0.1', 24);
print parse_ipv4_mask('192.1.168.2', 1000);
print parse_ipv4_mask('192.1.168.3', 31);
print parse_ipv4_mask('abc', 31);
print parse_ipv6('127.0.0.1');
print parse_ipv6('fe80::85d:e82c:9446:7994');
print parse_ipv6_mask("127.0.0.1", 24);
print parse_ipv6_mask("192.168.255.255", 120);
print parse_ipv6_mask("192.168.255.255/24", 124);
print parse_ipv6_mask("255.255.255.255", 128);
print parse_ipv6_mask("::192.168.255.255", 128);
print parse_ipv6_mask("::192.168.255.255/24", 128);
print parse_ipv6_mask("fe80::85d:e82c:9446:7994", 120);
print parse_ipv6_mask("fe80::85d:e82c:9446:7994", 128);
print parse_ipv6_mask("fe80::85d:e82c:9446:7994/120", 124);
print parse_json('{"a":123.5, "b":"{\\"c\\":456}"}');
print parse_json(dynamic([1, 2, 3]));
print parse_url('scheme://username:password@host:1234/this/is/a/path?k1=v1&k2=v2#fragment');
print parse_urlquery('k1=v1&k2=v2&k3=v3');
print parse_version('1.2');
print parse_version('1.2.4.5.6');
print parse_version('moo');
print parse_version('moo.boo.foo');
print parse_version(42);
print parse_version(strcat('1.', '2'));
print parse_version(strcat_delim('.', 'moo', 'boo', 'foo'));
print real(+inf);
print real(-inf);
print real(0.01);
print real(nan);
print real(null);
print repeat("asd", 3);
print repeat(1, -3);
print repeat(1, 0);
print repeat(1, 3);
print repeat(6.7,-4);
print repeat(timespan(1d), 3);
print repeat(true, 3);
print replace_regex(strcat('Number is ', '1'), 'is (\d+)', 'was: \1');
print result=parse_csv('aa,b,cc');
print result_multi_record=parse_csv('record1,a,b,c\nrecord2,x,y,z');
print reverse("asd");
print reverse('');
print reverse(123);
print reverse(123.34);
print reverse(datetime(2017-10-15 12:00));
print reverse(dynamic(['Darth', "Vader"]));
print reverse(dynamic([1, 2, 3]));
print reverse(dynamic([]));
print set_difference(dynamic([1, 1, 2, 2, 3, 3]), dynamic([1, 2, 3]));
print set_difference(dynamic([4]), dynamic([1, 2, 3]));
print set_difference(dynamic([]), dynamic(["asd"]));
print set_difference(dynamic([]), dynamic([9]));
print set_difference(dynamic([]), dynamic([]));
print set_has_element(dynamic(["this", "is", "an", "example"]), "example");
print set_has_element(dynamic(["this", "is", "an", "example"]), "examplee");
print set_has_element(dynamic([1, 2, 3, 4.2]), 4);
print set_has_element(dynamic([1, 2, 3]), 2);
print set_has_element(dynamic([]), 9);
print set_intersect(dynamic(['a', 's', 'd']), dynamic(['a', 'f']));
print set_intersect(dynamic(['Chewbacca', 'Darth Vader', 'Han Solo']), dynamic(['Darth Sidious', 'Darth Vader']));
print set_intersect(dynamic([1, 2, 3, 4, 5]), dynamic([1, 3, 5]), dynamic([2, 5]));
print set_intersect(dynamic([1, 2, 3]), dynamic([]));
print set_intersect(dynamic([4]), dynamic([1, 2, 3]));
print set_intersect(dynamic([]), dynamic([]));
print set_union(dynamic([]), dynamic([]));
print startofday(datetime(2017-01-01 10:10:17));
print startofday(datetime(2017-01-01 10:10:17), -1);
print startofday(datetime(2017-01-01 10:10:17), 1);
print startofweek(datetime(2017-01-01 10:10:17));
print startofweek(datetime(2017-01-01 10:10:17), -1);
print startofweek(datetime(2017-01-01 10:10:17), 1);
print startofyear(datetime(2017-01-01 10:10:17));
print startofyear(datetime(2017-01-01 10:10:17), -1);
print startofyear(datetime(2017-01-01 10:10:17), 1);
print strcmp('ABC','ABC'), strcmp('abc','ABC'), strcmp('ABC','abc'), strcmp('abcde','abc');
print substring("ABCD", -2, 2);
print time('12:30:55.123');
print time('14.02:03:04.12345');
print time(-1d);
print time(1d);
print time(2) + 1d;
print time(2);
print time(6nanoseconds);
print time(6tick);
print timespan('12.23:12:23') / timespan(1s);
print timespan(2d);
print todatetime("2015-12-24") == datetime(2015-12-24);
print todatetime('abc') == null;
print todecimal('abc');
print todecimal(123.345);
print todecimal(null);
print todouble('123.4');
print todouble('abc') == null;
print toint("123") == int(123);
print toint('abc');
print tolong('123');
print tolong('abc');
print toreal("123.4");
print toreal('abc') == null;
print tostring(123);
print tostring(null) == '';
print totimespan('0.00:01:00');
print totimespan('12.23:12:23') / totimespan(1s);
print totimespan('abc');
print totimespan(1tick);
print translate('krasp', 'otsku', 'spark'), translate('abc', '', 'ab'), translate('abc', 'x', 'abc');
print trim("", " asd ");
print trim("[^\w]+", strcat("- ","Te st", "1", "// $"));
print trim("^a", "asd");
print trim("a$", "asd");
print trim_end("://www.ibm.com", "https://www.ibm.com");
print trim_end("[^\w]+", strcat("- ","Te st", "1", "// $"));
print trim_end("^a", "asd");
print trim_end("^asd", "asd");
print trim_end("^asd", "wasd");
print trim_start("[^\w]+", strcat("- ","Te st", "1", "// $"));
print trim_start("asd$", "asd");
print trim_start("asd$", "asdw");
print trim_start("d$", "asd");
print trim_start("https://", "https://www.ibm.com");
print unixtime_microseconds_todatetime(1546300800000000);
print unixtime_milliseconds_todatetime(1546300800000);
print unixtime_nanoseconds_todatetime(1546300800000000000);
print unixtime_seconds_todatetime(-1d);
print unixtime_seconds_todatetime(1546300800);
print unixtime_seconds_todatetime(1d);
print v1=format_datetime(datetime(2017-01-29 09:00:05),'yy-MM-dd [HH:mm:ss]'), v2=format_datetime(datetime(2017-01-29 09:00:05), 'yyyy-M-dd [H:mm:ss]'), v3=format_datetime(datetime(2017-01-29 09:00:05), 'yy-MM-dd [hh:mm:ss tt]');
print v1=format_timespan(time('29.09:00:05.12345'), 'dd.hh:mm:ss:FF');
print v1=make_timespan(1,12), v2=make_timespan(1,12,30), v3=make_timespan(1,12,30,55.123);
print week_of_year(datetime(2000-01-01));
print x = 19 | extend = 4 + ;
print year = datetime_diff('year',datetime(2017-01-01),datetime(2000-12-31)), quarter = datetime_diff('quarter',datetime(2017-07-01),datetime(2017-03-30)), month = datetime_diff('month',datetime(2017-01-01),datetime(2015-12-30)), week = datetime_diff('week',datetime(2017-10-29 00:00),datetime(2017-09-30 23:59)), day = datetime_diff('day',datetime(2017-10-29 00:00),datetime(2017-09-30 23:59)), hour = datetime_diff('hour',datetime(2017-10-31 01:00),datetime(2017-10-30 23:59)), minute = datetime_diff('minute',datetime(2017-10-30 23:05:01),datetime(2017-10-30 23:00:59)), second = datetime_diff('second',datetime(2017-10-30 23:00:10.100),datetime(2017-10-30 23:00:00.900));
print year = datetime_part("year", datetime(2017-10-30 01:02:03.7654321)),quarter = datetime_part("quarter", datetime(2017-10-30 01:02:03.7654321)),month = datetime_part("month", datetime(2017-10-30 01:02:03.7654321)),weekOfYear = datetime_part("week_of_year", datetime(2017-10-30 01:02:03.7654321)),day = datetime_part("day", datetime(2017-10-30 01:02:03.7654321)),dayOfYear = datetime_part("dayOfYear", datetime(2017-10-30 01:02:03.7654321)),hour = datetime_part("hour", datetime(2017-10-30 01:02:03.7654321)),minute = datetime_part("minute", datetime(2017-10-30 01:02:03.7654321)),second = datetime_part("second", datetime(2017-10-30 01:02:03.7654321));
print year_month_day_hour_minute = make_datetime(2017,10,01,12,10);
print year_month_day_hour_minute_second = make_datetime(2017,10,01,12,11,0.1234567);
print zip(dynamic([1,2,3]), dynamic([10,20]));
print zip(dynamic([1,3,5]), dynamic([2,4,6]));
print zip(dynamic([]), dynamic([1,2,3]));
print zip(dynamic([]), dynamic([]));
random_key:value_with_comma,still_part_of_value:still_part_of_value;
rename database db_hang_temp to db_hang;
RENAME DATABASE {old_db_name:Identifier} TO {new_db_name:Identifier};
RENAME DICTIONARY dummy_db.dict1 TO test_01191.dict;
RENAME DICTIONARY test_01155_atomic.dict TO test_01155_ordinary.dict;
RENAME DICTIONARY test_01155_ordinary.dict TO test_01155_atomic.dict;
RENAME DICTIONARY test_01155_ordinary.dict TO test_01155_ordinary.dict1;
RENAME DICTIONARY test_01191.dict TO dummy_db.dict1;
RENAME DICTIONARY test_01191.dict TO test_01191.dict1;
RENAME DICTIONARY test_01191.dict1 TO test_01191.dict2;
RENAME DICTIONARY test_01191.t TO test_01191.dict1;
RENAME DICTIONARY test_01191.table TO test_01191.table1;
RENAME DICTIONARY {new_db_name:Identifier}.{old_dict_name:Identifier} TO {new_db_name:Identifier}.{new_dict_name:Identifier};
RENAME TABLE 02265_ordinary_db.join_table TO 02265_atomic_db.join_table;
rename table db_hang.test to db_hang_temp.test;
rename table db_hang.test_mv to db_hang_temp.test_mv;
RENAME TABLE if exists t0 TO t1;
RENAME TABLE original_mv TO new_mv;
RENAME TABLE rename2 TO rename3;
RENAME TABLE rmt TO rmt1;
RENAME TABLE rmt TO rmt2;
RENAME TABLE set TO set2;
RENAME TABLE set2 TO set;
RENAME TABLE sqllt.table TO sqllt.table_new;
RENAME TABLE sqllt.table_new TO sqllt.table;
RENAME TABLE t0 TO t1;
RENAME TABLE t0_tmp TO t1;
RENAME TABLE t1 TO t1tmp, t2 TO t2tmp;
rename table t1 to t2;
RENAME TABLE t1tmp TO t2, t2tmp TO t1;
rename table t2 to t1;
RENAME TABLE test1601_detach_permanently_atomic.test_name_rename_attempt TO test1601_detach_permanently_atomic.test_name_reuse;
RENAME TABLE test1601_detach_permanently_lazy.test_name_rename_attempt TO test1601_detach_permanently_lazy.test_name_reuse;
RENAME TABLE test1601_detach_permanently_ordinary.test_name_rename_attempt TO test1601_detach_permanently_ordinary.test_name_reuse;
RENAME TABLE test1_00843 TO test2_00843;
RENAME TABLE test_01148_atomic.rmt3 to test_01148_ordinary.rmt3;
RENAME TABLE test_01148_atomic.rmt4 to test_01148_atomic.rmt3;
RENAME TABLE test_01155_atomic.dist TO test_01155_ordinary.dist;
RENAME TABLE test_01155_atomic.dst TO test_01155_ordinary.dst;
RENAME TABLE test_01155_atomic.mv1 TO test_01155_ordinary.mv1;
RENAME TABLE test_01155_atomic.mv2 TO test_01155_ordinary.mv2;
RENAME TABLE test_01155_atomic.src TO test_01155_ordinary.src;
RENAME TABLE test_01155_ordinary.dict1 TO test_01155_ordinary.dict;
RENAME TABLE test_01155_ordinary.dst TO test_01155_atomic.dst;
RENAME TABLE test_01155_ordinary.mv1 TO test_01155_atomic.mv1;
RENAME TABLE test_01155_ordinary.mv2 TO test_01155_atomic.mv2;
RENAME TABLE test_01155_ordinary.src TO test_01155_atomic.src;
rename table test_1603_rename_bug_atomic.bar to test_1603_rename_bug_atomic.foo;
rename table test_1603_rename_bug_ordinary.bar to test_1603_rename_bug_ordinary.foo;
rename table v_test1 to v_test11, v_test2 to v_test22;
RENAME TABLE {CLICKHOUSE_DATABASE:Identifier}.r1 TO {CLICKHOUSE_DATABASE:Identifier}.r1_bak;
RENAME TABLE {new_db_name:Identifier}.{old_tbl_name:Identifier} TO {new_db_name:Identifier}.{new_tbl_name:Identifier};
RENAME {CLICKHOUSE_DATABASE:Identifier} TO {CLICKHOUSE_DATABASE_1:Identifier};
RENAME {CLICKHOUSE_DATABASE:Identifier}.r1 TO {CLICKHOUSE_DATABASE:Identifier}.r1_bak,    {CLICKHOUSE_DATABASE:Identifier}.r2 TO {CLICKHOUSE_DATABASE:Identifier}.r2_bak;
RENAME {CLICKHOUSE_DATABASE:Identifier}.r1_bak TO {CLICKHOUSE_DATABASE:Identifier}.r1;
RENAME {CLICKHOUSE_DATABASE:Identifier}.test_dictionary TO {CLICKHOUSE_DATABASE:Identifier}.test_dictionary_2;
REPLACE DICTIONARY 01913_db.test_dictionary (   id UInt64,   value_1 String ) PRIMARY KEY id LAYOUT(HASHED()) SOURCE(CLICKHOUSE(DB '01913_db' TABLE 'test_source_table_2')) LIFETIME(0);
replace table buf (n int) engine=Buffer(currentDatabase(), dist, 1, 10, 100, 10, 100, 1000, 1000);
replace table buf (n int) engine=Distributed(test_shard_localhost, currentDatabase(), dist);
replace table buf (n int) engine=Null;
replace table dist (n int) engine=Buffer(currentDatabase(), t, 1, 10, 100, 10, 100, 1000, 1000);
replace table dist (n int) engine=Distributed(test_shard_localhost, currentDatabase(), t);
replace table dist (n int) engine=Null;
replace table join engine=Join(ANY, INNER, n) as select * from t where throwIf(n);
replace table t1 (n UInt64) engine=MergeTree order by n;
replace table t1 (n UInt64, s String) engine=MergeTree order by n;
rollback;

SET   allow_experimental_parallel_reading_from_replicas=1,   max_parallel_replicas=2,   use_hedged_requests=0,   cluster_for_parallel_replicas='test_cluster_one_shard_three_replicas_localhost',   parallel_replicas_for_non_replicated_merge_tree=1 ;
set aggregate_functions_null_for_empty = 1;
SET aggregate_functions_null_for_empty = 1;
SET aggregate_functions_null_for_empty=0;
set aggregate_functions_null_for_empty=0;
SET aggregate_functions_null_for_empty=1;
SET allow_ddl = 0;
set allow_deprecated_database_ordinary=1;
set allow_deprecated_syntax_for_merge_tree=1;
SET allow_deprecated_syntax_for_merge_tree=1;
SET allow_experimental_alter_materialized_view_structure = 1;
SET allow_experimental_analyzer = 0, join_use_nulls = 0;
SET allow_experimental_analyzer = 0, join_use_nulls = 1;
SET allow_experimental_analyzer = 0;
set allow_experimental_analyzer = 0;
SET allow_experimental_analyzer = 1, join_use_nulls = 0;
SET allow_experimental_analyzer = 1, join_use_nulls = 1;
SET allow_experimental_analyzer = 1;
SET allow_experimental_parallel_reading_from_replicas=1, max_parallel_replicas=3, cluster_for_parallel_replicas='test_cluster_one_shard_three_replicas_localhost';
SET allow_experimental_parallel_reading_from_replicas=1, max_parallel_replicas=3, parallel_replicas_for_non_replicated_merge_tree=1;
SET allow_experimental_parallel_reading_from_replicas=2, max_parallel_replicas=11, cluster_for_parallel_replicas='parallel_replicas', parallel_replicas_for_non_replicated_merge_tree=1;
SET allow_experimental_parallel_reading_from_replicas=2, max_parallel_replicas=3, parallel_replicas_for_non_replicated_merge_tree=1;
SET allow_experimental_parallel_reading_from_replicas=2;
SET allow_experimental_statistic = 1;
SET allow_experimental_usearch_index = 1;
SET allow_experimental_window_view = 1;
set allow_experimental_window_view = 1;
SET allow_hyperscan = 0;
SET allow_introspection_functions = 1;
SET allow_non_metadata_alters = 0;
SET allow_nonconst_timezone_arguments = 1;
set allow_nondeterministic_mutations=1;
set allow_prefetched_read_pool_for_local_filesystem = 0;
SET allow_prefetched_read_pool_for_remote_filesystem=1;
set allow_settings_after_format_in_insert=1;
SET allow_simdjson=0;
SET allow_simdjson=1;
SET allow_statistic_optimize = 1;
SET allow_suspicious_codecs = 0;
SET allow_suspicious_codecs = 1;
set allow_suspicious_low_cardinality_types = 1;
set allow_suspicious_low_cardinality_types=1;
SET allow_suspicious_ttl_expressions = 1;
set alter_sync = 0;
SET alter_sync = 0;
SET alter_sync = 1;
SET alter_sync = 2;
SET any_join_distinct_right_table_keys = 0;
SET any_join_distinct_right_table_keys = 1;
set any_join_distinct_right_table_keys = 1;
SET async_insert = 1;
SET async_insert_busy_timeout_ms = 1000000;
SET async_insert_busy_timeout_ms = 100000;
SET async_insert_deduplicate = 1;
SET bool_false_representation = 'Custom false';
set bool_false_representation='False';
set bool_false_representation='No';
set bool_false_representation='Off';
SET bool_true_representation = 'Custom true';
set bool_true_representation='On';
set bool_true_representation='True';
set bool_true_representation='Yes';
SET calculate_text_stack_trace = 0;
SET cast_ipv4_ipv6_default_on_conversion_error = 0;
SET cast_ipv4_ipv6_default_on_conversion_error = 1;
SET cast_keep_nullable = 0;
SET cast_keep_nullable = 1;
set cast_keep_nullable = 1;
SET check_query_single_value_result = 'false';
SET check_query_single_value_result = 0;
SET check_query_single_value_result = 1;
SET check_referential_table_dependencies = 0;
SET check_referential_table_dependencies = 1;
SET check_table_dependencies=0;
set check_table_dependencies=0;
SET check_table_dependencies=1;
set cluster_for_parallel_replicas = 'test_cluster_one_shard_three_replicas_localhost';
SET cluster_for_parallel_replicas = 'test_cluster_one_shard_three_replicas_localhost';
SET cluster_for_parallel_replicas='';
set compatibility = '22.3';
set compatibility = '22.4';
set compatibility='a.a';
set compatibility_ignore_auto_increment_in_create_table=false;
set compatibility_ignore_auto_increment_in_create_table=true;
SET compile_aggregate_expressions = 1;
SET compile_aggregate_expressions=1;
set compile_aggregate_expressions=1;
SET compile_expressions = 1;
set compile_expressions = 1;
SET compile_expressions=true;
SET connections_with_failover_max_tries=0;
SET convert_query_to_cnf = 0;
set convert_query_to_cnf = 0;
SET convert_query_to_cnf = 1;
SET count_distinct_implementation = 'uniq';
SET count_distinct_implementation = 'uniqCombined';
SET count_distinct_implementation = 'uniqExact';
SET count_distinct_implementation = 'uniqTheta';
set count_distinct_optimization = 1;
set count_distinct_optimization=false;
set count_distinct_optimization=true;
SET create_index_ignore_unique=1;
SET cross_to_inner_join_rewrite = 1;
SET cross_to_inner_join_rewrite = 2;
SET custom_a = 'changed';
SET custom_a = 5;
SET custom_b = -177;
SET custom_b = NULL;
SET custom_c = 50000;
SET custom_c = 98.11;
SET custom_compound.identifier.v1 = 'test';
SET custom_d = 'abc def';
SET custom_d = 1.11;
SET custom_null = NULL;
SET data_type_default_nullable='false';
set database_atomic_wait_for_drop_and_detach_synchronously=0;
set database_atomic_wait_for_drop_and_detach_synchronously=1;
set date_time_input_format = 'basic';
SET date_time_input_format = 'best_effort';
set date_time_input_format = 'best_effort';
set date_time_input_format = 'best_effort_us';
SET date_time_output_format = 'iso';
SET date_time_output_format = 'simple';
SET date_time_output_format = 'unix_timestamp';
SET date_time_output_format='iso';
SET date_time_overflow_behavior = 'ignore';
SET date_time_overflow_behavior = 'saturate';
SET date_time_overflow_behavior = 'throw';
SET decimal_check_overflow = 0;
set deduplicate_blocks_in_dependent_materialized_views=0;
set deduplicate_blocks_in_dependent_materialized_views=1;
SET DEFAULT ROLE ALL EXCEPT r1_01292 TO u5_01292;
SET DEFAULT ROLE ALL TO u4_01292;
SET DEFAULT ROLE NONE TO u6_01292;
SET DEFAULT ROLE r1_01292, r2_01292 TO u2_01292, u3_01292, u4_01292;
SET DEFAULT ROLE r2_01292 TO u3_01292;
SET DEFAULT ROLE sqllt_role TO sqllt_user;
SET default_max_bytes_in_join = 0;
SET default_max_bytes_in_join = 10000000;
SET default_table_engine = 'Log';
SET default_table_engine = 'Memory';
SET default_table_engine = 'MergeTree';
SET default_table_engine = 'None';
set default_table_engine='MergeTree';
SET default_table_engine='MergeTree';
set default_table_engine='ReplicatedMergeTree';
SET default_temporary_table_engine = 'Log';
SET describe_compact_output = 0, describe_include_virtual_columns = 0, describe_include_subcolumns = 1;
SET describe_compact_output = 1, describe_include_virtual_columns = 1, describe_include_subcolumns = 1;
set dialect = 'kusto';
set dialect='kusto';
SET distributed_aggregation_memory_efficient = 0;
SET distributed_aggregation_memory_efficient = 1,   group_by_two_level_threshold = 1000,   group_by_overflow_mode = 'any',   max_rows_to_group_by = 1000,   totals_mode = 'after_having_auto';
set distributed_aggregation_memory_efficient = 1, group_by_two_level_threshold = 1, group_by_two_level_threshold_bytes=1;
set distributed_aggregation_memory_efficient=1;
SET distributed_ddl_output_mode='none';
set distributed_ddl_output_mode='throw';
SET distributed_ddl_output_mode='throw';
SET distributed_foreground_insert = 0, network_compression_method = 'zstd';
SET distributed_foreground_insert = 1;
set distributed_foreground_insert = 1;
SET distributed_foreground_insert=0;
SET distributed_foreground_insert=1;
set distributed_foreground_insert=1;
SET distributed_group_by_no_merge = 1, extremes = 0;
SET distributed_group_by_no_merge = 1, extremes = 1;
set distributed_product_mode = 'global';
set distributed_product_mode = 'local';
SET distributed_product_mode = 'local';
SET do_not_merge_across_partitions_select_final = 1;
SET do_not_merge_across_partitions_select_final=1;
set drain_timeout = 123123;
set drain_timeout = 3;
SET empty_result_for_aggregation_by_empty_set = 0;
set empty_result_for_aggregation_by_empty_set = 0;
SET empty_result_for_aggregation_by_empty_set = 1;
set empty_result_for_aggregation_by_empty_set=1;
SET enable_filesystem_cache = 0;
SET enable_filesystem_cache=0;
set enable_filesystem_cache_on_write_operations=0;
SET enable_filesystem_cache_on_write_operations=0;
SET enable_global_with_statement = 0;
set enable_global_with_statement = 1;
set enable_global_with_statement=0;
set enable_global_with_statement=1;
set enable_memory_bound_merging_of_aggregation_results = 1;
SET enable_multiple_prewhere_read_steps = 1;
SET enable_multiple_prewhere_read_steps=1, move_all_conditions_to_prewhere=1;
SET enable_multiple_prewhere_read_steps=true, move_all_conditions_to_prewhere=true;
SET enable_optimize_predicate_expression = 0;
set enable_optimize_predicate_expression=1;
SET enable_positional_arguments = 0;
set enable_positional_arguments = 0;
set enable_positional_arguments = 1;
set enable_positional_arguments=0;
SET enable_positional_arguments=0;
set engine_file_allow_create_multiple_files = 1;
SET engine_file_empty_if_not_exists=0;
set engine_file_truncate_on_insert = 1;
SET engine_file_truncate_on_insert=0;
SET engine_file_truncate_on_insert=1;
set engine_file_truncate_on_insert=1;
set exact_rows_before_limit = 1, output_format_write_statistics = 0, max_block_size = 100;
set except_default_mode = 'DISTINCT';
SET extract_kvp_max_pairs_per_row = 0;
set extremes = '1';
SET extremes = 1;
set extremes = 1;
SET filesystem_cache_max_download_size=128;
set final = 0;
set final = 1;
set final=1;
set flatten_nested = 1;
set force_aggregate_partitions_independently = 1;
SET force_index_by_date = 0;
SET force_index_by_date = 1;
set force_index_by_date=0;
set force_index_by_date=1;
set force_optimize_projection = 1, optimize_use_projections = 1;
set force_optimize_skip_unused_shards=2;
set force_optimize_skip_unused_shards_nesting=2;
SET force_primary_key = 0;
set force_primary_key = 0;
SET force_primary_key = 1, enable_optimize_predicate_expression = 1;
SET force_primary_key = 1, force_index_by_date=1;
SET force_primary_key = 1;
set force_primary_key = 1;
set force_primary_key=0;
set force_primary_key=1;
set format_avro_schema_registry_url = '';
set format_avro_schema_registry_url = 'https://github.com/ClickHouse/ClickHouse/tree/master/src/Core';
set format_csv_delimiter = ',';
SET format_csv_null_representation = '\\N';
SET format_csv_null_representation = '';
set format_custom_escaping_rule='CSV', format_custom_field_delimiter='<field_delimiter>', format_custom_row_before_delimiter='<row_before_delimiter>', format_custom_row_after_delimiter='<row_after_delimiter>', format_custom_row_between_delimiter='<row_between_delimiter>', format_custom_result_before_delimiter='<result_before_delimiter>', format_custom_result_after_delimiter='<result_after_delimiter>';
SET function_range_max_elements_in_block = 10;
SET group_by_overflow_mode = 'any', max_rows_to_group_by = 1000, totals_mode = 'after_having_auto';
SET group_by_overflow_mode = 'any';
SET group_by_overflow_mode = 'throw';
set group_by_overflow_mode='any';
SET group_by_two_level_threshold = '100K';
SET group_by_two_level_threshold = 1, max_threads = 1;
SET group_by_two_level_threshold = 1000000;
SET group_by_two_level_threshold = 100000;
SET group_by_two_level_threshold_bytes = '50M';
SET group_by_two_level_threshold_bytes = 1;
SET group_by_two_level_threshold_bytes = 50000000;
SET group_by_use_nulls = 0;
SET group_by_use_nulls = 1;
set ignore_materialized_views_with_dropped_target_table = 1;
SET implicit_transaction=1;
SET implicit_transaction=False;
set input_format_arrow_import_nested=1;
SET input_format_csv_enum_as_number = 0;
SET input_format_csv_enum_as_number = 1;
set input_format_csv_try_infer_numbers_from_strings=1;
set input_format_defaults_for_omitted_fields = 1;
set input_format_json_try_infer_named_tuples_from_objects = 1;
set input_format_json_try_infer_named_tuples_from_objects=0;
set input_format_json_try_infer_numbers_from_strings=1;
set input_format_max_rows_to_read_for_schema_inference=2;
SET input_format_null_as_default = 0;
SET input_format_null_as_default = 1;
set input_format_null_as_default = 1;
set input_format_null_as_default=0;
set input_format_orc_filter_push_down = 1;
set input_format_orc_import_nested=1;
set input_format_orc_row_batch_size = 100;
set input_format_parallel_parsing=1;
set input_format_parquet_import_nested = 1;
SET input_format_skip_unknown_fields = 1;
set input_format_try_infer_datetimes=1;
SET input_format_tsv_enum_as_number = 0;
SET input_format_tsv_enum_as_number = 1;
SET input_format_values_accurate_types_of_literals = 0;
SET input_format_values_interpret_expressions = 0;
SET input_format_values_interpret_expressions = 1;
SET input_format_values_interpret_expressions=0;
SET insert_allow_materialized_columns = 1;
SET insert_allow_materialized_columns=0;
SET insert_allow_materialized_columns=1;
SET insert_deduplicate=0;
set insert_deduplication_token = '';
set insert_deduplication_token = '1';
SET insert_deduplication_token = '1';
set insert_deduplication_token = '2';
SET insert_deduplication_token = '2';
SET insert_deduplication_token = '3';
set insert_deduplication_token = '\x61\x00\x62';
set insert_deduplication_token = '\x61\x00\x63';
set insert_distributed_one_random_shard = 1;
SET insert_keeper_fault_injection_probability=0;
set insert_keeper_fault_injection_probability=0;
SET insert_keeper_max_retries = 0;
SET insert_keeper_max_retries=100;
set insert_keeper_retry_max_backoff_ms=10;
SET insert_keeper_retry_max_backoff_ms=10;
set insert_null_as_default=1;
SET insert_quorum = 'auto';
SET insert_quorum = 0;
set insert_quorum = 0;
set insert_quorum = 123123;
SET insert_quorum = 1;
SET insert_quorum = 2, insert_quorum_parallel = 0;
SET insert_quorum = 2;
SET insert_quorum=2, insert_quorum_parallel=0;
SET insert_quorum=2, insert_quorum_parallel=1;
SET insert_quorum=3;
SET insert_quorum_parallel=1;
SET insert_quorum_timeout = 5000;
SET insert_quorum_timeout = 600000;
SET insert_quorum_timeout=0;
SET insert_quorum_timeout=100;
SET insert_quorum_timeout=6000000;
SET invalid_custom = 8;
SET join_algorithm = 'auto';
set join_algorithm = 'auto,direct';
set join_algorithm = 'default';
set join_algorithm = 'partial_merge';
SET join_algorithm = 'prefer_partial_merge';
set join_algorithm='grace_hash';
SET join_algorithm='partial_merge';
SET join_default_strictness = '';
SET join_default_strictness = 'ALL';
SET join_on_disk_max_files_to_merge = 4;
SET join_use_nulls = 0;
set join_use_nulls = 0;
SET join_use_nulls = 1;
set join_use_nulls = 1;
SET joined_subquery_requires_alias = 0, join_algorithm = 'partial_merge';
SET joined_subquery_requires_alias = 0;
set joined_subquery_requires_alias=0, allow_experimental_analyzer=0;
SET keeper_map_strict_mode = 1;
SET keeper_map_strict_mode = false;
SET keeper_map_strict_mode = true;
SET legacy_column_name_of_tuple_literal=1;
SET limit = 3;
SET limit = 4;
set limit=1;
set load_marks_asynchronously = 0;
SET local_filesystem_read_method = 'mmap', min_bytes_to_use_mmap_io = 1;
set local_filesystem_read_method = 'pread';
SET local_filesystem_read_method = 'pread';
SET local_filesystem_read_method='pread';
SET local_filesystem_read_prefetch=1;
SET log_comment = '02306_part_types_profile_events';
SET log_comment = 'async_insert_skip_settings_1';
SET log_comment = 'async_insert_skip_settings_2';
SET log_comment = 'async_insert_skip_settings_3';
SET log_comment = 'async_insert_skip_settings_4';
SET log_comment = 'log_comment test', log_queries = 1;
SET log_comment='';
set log_formatted_queries = 1;
SET log_profile_events=false;
SET log_profile_events=true;
SET log_queries = 0;
set log_queries = 1;
SET log_queries=0;
set log_queries=1;
SET log_queries=1;
set log_queries_min_query_duration_ms=300000;
set log_queries_min_type='EXCEPTION_BEFORE_START';
set log_queries_min_type='EXCEPTION_WHILE_PROCESSING';
set log_queries_min_type='QUERY_FINISH';
SET log_queries_min_type='QUERY_FINISH';
SET log_query_threads = 1;
set log_query_threads=0;
set log_query_threads=1;
set materialize_ttl_after_modify = 0;
SET materialize_ttl_after_modify = 0;
set max_alter_threads = 0;
set max_alter_threads = 123123;
SET max_analyze_depth = 1;
SET max_ast_depth = 10_000_000;
SET max_block_size = 0;
SET max_block_size = 1, min_insert_block_size_rows = 0, min_insert_block_size_bytes = 0;
SET max_block_size = 10, max_threads = 1;
SET max_block_size = 10, min_insert_block_size_rows = 0, min_insert_block_size_bytes = 0, max_threads = 20;
set max_block_size = 1000, enable_unaligned_array_join = true;
SET max_block_size = 1000, min_insert_block_size_rows = 0, min_insert_block_size_bytes = 0;
set max_block_size = 100000, enable_unaligned_array_join = true;
SET max_block_size = 1000000;
set max_block_size = 100000;
SET max_block_size = 100001;
SET max_block_size = 10000;
SET max_block_size = 1000;
SET max_block_size = 100;
set max_block_size = 1024;
set max_block_size = 1048576;
SET max_block_size = 10;
SET max_block_size = 1;
set max_block_size = 1;
SET max_block_size = 6;
SET max_block_size = 8192;
SET max_block_size = 8200;
SET max_bytes_before_external_group_by = 0;
set max_bytes_before_external_group_by = 1000000000;
SET max_bytes_before_external_group_by = 1000000;
set max_bytes_before_external_group_by = 16;
SET max_bytes_before_external_group_by = 1;
SET max_bytes_before_external_group_by = 200000000;
set max_bytes_before_external_group_by=0;
SET max_bytes_before_external_group_by=1;
SET max_bytes_before_external_sort = 20000000;
SET max_bytes_before_external_sort = 33554432;
SET max_bytes_before_remerge_sort = 1000000;
SET max_bytes_in_join = '100', join_algorithm = 'auto';
SET max_bytes_in_join = '100';
SET max_bytes_in_join = 10000000;
SET max_bytes_in_join = 100;
SET max_columns_to_read = 1;
set max_columns_to_read=1;
SET max_distributed_connections=1;
set max_distributed_connections=1;
SET max_execution_speed = 0;
SET max_execution_speed = 1, max_execution_time = 3;
SET max_execution_speed = 1000000;
SET max_execution_speed_bytes = 0;
SET max_execution_speed_bytes = 8000000;
set max_execution_time = 0.5, timeout_overflow_mode = 'break';
SET max_execution_time = 100,   timeout_before_checking_execution_speed = 100,   max_execution_speed = 1000000,   max_threads = 1,   max_block_size = 1000000;
SET max_execution_time=0.1;
set max_hyperscan_regexp_total_length = 1;
set max_insert_block_size = 1;
SET max_insert_block_size=100000;
SET max_insert_block_size=DEFAULT;
SET max_insert_threads = 1, max_threads = 100, min_insert_block_size_rows = 1048576, max_block_size = 65536;
SET max_insert_threads = 1;
set max_insert_threads = 1;
set max_insert_threads = 4;
set max_insert_threads=2;
SET max_joined_block_size_rows = 10000000;
SET max_joined_block_size_rows = 2000;
SET max_joined_block_size_rows = 2;
SET max_memory_usage = '1234ki';
SET max_memory_usage = '1234Ki';
SET max_memory_usage = '410M';
SET max_memory_usage = '500M';
SET max_memory_usage = 0;
SET max_memory_usage = 100000000, max_threads = 2;
SET max_memory_usage = 10000000000;
SET max_memory_usage = 1000000000;
SET max_memory_usage = 8000000;
set max_memory_usage='10Mi', max_untracked_memory=0;
SET max_memory_usage=10e6;
SET max_parallel_replicas = 1;
SET max_parallel_replicas = 2;
SET max_parallel_replicas = 3, prefer_localhost_replica = 1, cluster_for_parallel_replicas = 'test_cluster_one_shard_three_replicas_localhost', allow_experimental_parallel_reading_from_replicas = 1;
SET max_parallel_replicas = 3;
set max_parallel_replicas = 3;
set max_parallel_replicas=2;
SET max_parallel_replicas=3, allow_experimental_parallel_reading_from_replicas=1, cluster_for_parallel_replicas='parallel_replicas';
SET max_parallel_replicas=3, cluster_for_parallel_replicas='test_cluster_one_shard_three_replicas_localhost', parallel_replicas_for_non_replicated_merge_tree=1;
SET max_parser_depth = 10000;
SET max_parser_depth = 4000;
set max_partitions_per_insert_block = 100;
SET max_partitions_per_insert_block = 1;
SET max_query_size = 1073741824;
SET max_query_size=262144;
SET max_query_size=29;
set max_read_buffer_size=1048576;
SET max_result_rows = 10;
SET max_rows_in_join = '10';
SET max_rows_in_join = 1000;
SET max_rows_in_set = 20;
SET max_rows_in_set_to_optimize_join = 0;
SET max_rows_in_set_to_optimize_join = 1000;
SET max_rows_to_group_by = 100000;
SET max_rows_to_group_by = 10;
SET max_rows_to_group_by = 3000, group_by_overflow_mode = 'any';
SET max_rows_to_group_by = 65535;
set max_rows_to_group_by=10;
SET max_rows_to_read = 0;
set max_rows_to_read = 0;
SET max_threads = 10;
set max_threads = 10;
SET max_threads = 12;
SET max_threads = 1500;
set max_threads = 16;
SET max_threads = 16;
SET max_threads = 1;
set max_threads = 1;
SET max_threads = 20;
SET max_threads = 2;
SET max_threads = 4;
set max_threads = 4;
SET max_threads = 5;
SET max_threads = nan;
set max_threads =1;
set max_threads =2;
set max_threads=0;
SET max_threads=0;
SET max_threads=1;
set max_threads=1;
set max_threads=2;
SET max_threads=3;
SET memory_profiler_sample_probability = 1;
SET memory_profiler_step = 1000000;
SET merge_tree_min_rows_for_concurrent_read=10000;
SET merge_tree_min_rows_for_seek = 0;
SET min_count_to_compile_expression = 0;
SET min_count_to_compile_expression = 1;
SET min_execution_speed = 0;
SET min_execution_speed_bytes = 0;
SET min_execution_speed_bytes = 800000000000, timeout_before_checking_execution_speed = 0;
SET min_insert_block_size_bytes = 0;
SET min_insert_block_size_bytes = 1000000;
SET min_insert_block_size_rows = 0, min_insert_block_size_bytes = 0;
SET min_insert_block_size_rows = 1000000;
SET min_insert_block_size_rows = 100;
SET min_insert_block_size_rows=0;
SET min_insert_block_size_rows=100e3;
SET move_all_conditions_to_prewhere = 1;
SET move_all_conditions_to_prewhere=1;
SET mutations_execute_nondeterministic_on_initiator = 1;
SET mutations_execute_subqueries_on_initiator = 1;
SET mutations_sync = 0;
SET mutations_sync = 1;
set mutations_sync = 1;
set mutations_sync = 2;
set mutations_sync=2;
SET mysql_max_rows_to_insert = 123123;
set mysql_max_rows_to_insert = 123123;
set mysql_max_rows_to_insert = 65536;
SET network_compression_method = 'lz4hc';
SET network_compression_method = 'zstd';
SET network_zstd_compression_level = 5;
SET network_zstd_compression_level = 7;
SET offset = 195;
SET offset = 1;
SET optimize_aggregation_in_order = 0;
set optimize_aggregation_in_order = 0;
SET optimize_aggregation_in_order = 1;
set optimize_aggregation_in_order = 1;
SET optimize_aggregation_in_order=1;
set optimize_aggregation_in_order=1;
set optimize_aggregators_of_group_by_keys = 0;
set optimize_aggregators_of_group_by_keys = 1;
SET optimize_aggregators_of_group_by_keys = 1;
SET optimize_aggregators_of_group_by_keys=1;
SET optimize_append_index = 0;
SET optimize_append_index = 1;
SET optimize_arithmetic_operations_in_aggregate_functions = 0;
set optimize_arithmetic_operations_in_aggregate_functions = 1;
SET optimize_arithmetic_operations_in_aggregate_functions = 1;
SET optimize_arithmetic_operations_in_aggregate_functions=1;
set optimize_distinct_in_order=1;
set optimize_distributed_group_by_sharding_key=1;
SET optimize_functions_to_subcolumns = 0;
SET optimize_functions_to_subcolumns = 1;
set optimize_group_by_function_keys = 0;
SET optimize_monotonous_functions_in_order_by = 1;
SET optimize_move_to_prewhere = 0;
set optimize_move_to_prewhere = 0;
SET optimize_move_to_prewhere = 1;
set optimize_move_to_prewhere=0;
SET optimize_move_to_prewhere=1;
SET optimize_move_to_prewhere_if_final = 0;
SET optimize_move_to_prewhere_if_final = 1;
SET optimize_multiif_to_if = 0;
set optimize_normalize_count_variants = 1;
SET optimize_on_insert = 0;
set optimize_on_insert = 0;
set optimize_or_like_chain = 0;
SET optimize_read_in_order = 1, query_plan_read_in_order = 1, allow_experimental_analyzer = 0;
SET optimize_read_in_order = 1, query_plan_read_in_order = 1, allow_experimental_analyzer = 1;
SET optimize_read_in_order = 1;
set optimize_read_in_order = 1;
SET optimize_read_in_order=0;
SET optimize_read_in_order=1;
set optimize_redundant_functions_in_order_by = 0;
set optimize_redundant_functions_in_order_by = 1;
set optimize_respect_aliases = 1, optimize_monotonous_functions_in_order_by = 1;
set optimize_rewrite_aggregate_function_with_if = false;
set optimize_rewrite_aggregate_function_with_if = true;
set optimize_rewrite_array_exists_to_has = false;
set optimize_rewrite_array_exists_to_has = true;
SET optimize_rewrite_sum_if_to_count_if = 0;
SET optimize_rewrite_sum_if_to_count_if = 1;
set optimize_rewrite_sum_if_to_count_if=0;
set optimize_rewrite_sum_if_to_count_if=1;
SET optimize_skip_merged_partitions=1;
SET optimize_skip_unused_shards = 1;
set optimize_skip_unused_shards=1;
set optimize_skip_unused_shards_nesting=1;
set optimize_skip_unused_shards_nesting=2;
set optimize_skip_unused_shards_rewrite_in=0;
SET optimize_sorting_by_input_stream_properties = 1;
set optimize_sorting_by_input_stream_properties=1;
SET optimize_substitute_columns = 1;
set optimize_syntax_fuse_functions = 0;
set prefer_localhost_replica = 0;
SET prefer_localhost_replica = 1;
set prefer_localhost_replica = 1;
set prefer_localhost_replica=0;
SET prefer_localhost_replica=0;
SET prefer_localhost_replica=1;
set prefer_localhost_replica=1;
set preferred_block_size_bytes = 0;
set preferred_block_size_bytes = 2000000;
SET preferred_block_size_bytes = 8192;
set preferred_max_column_in_block_size_bytes = 0;
set preferred_max_column_in_block_size_bytes = 112;
set preferred_max_column_in_block_size_bytes = 1152;
set preferred_max_column_in_block_size_bytes = 128;
set preferred_max_column_in_block_size_bytes = 2097152;
set preferred_max_column_in_block_size_bytes = 256;
SET preferred_max_column_in_block_size_bytes = 32;
set preferred_max_column_in_block_size_bytes = 4194304;
set preferred_max_column_in_block_size_bytes = 96;
set print_pretty_type_names=1;
SET query_cache_max_entries = 1;
SET query_cache_max_entries = DEFAULT;
SET query_cache_max_size_in_bytes = 1;
SET query_cache_max_size_in_bytes = DEFAULT;
set query_plan_filter_push_down = true;
set query_plan_remove_redundant_sorting=0;
SET query_profiler_cpu_time_period_ns = 0;
SET query_profiler_cpu_time_period_ns = 1000000;
SET query_profiler_real_time_period_ns = 0;
SET query_profiler_real_time_period_ns = 1000000000;
SET query_profiler_real_time_period_ns = 100000000;
SET read_in_order_two_level_merge_threshold=1000000;
SET read_in_order_two_level_merge_threshold=100;
SET read_in_order_two_level_merge_threshold=1;
set read_in_order_two_level_merge_threshold=1;
SET read_overflow_mode = 'break';
SET read_overflow_mode = 'throw';
SET readonly = 2;
set remote_filesystem_read_method = 'read';
SET remote_filesystem_read_method = 'read';
SET replication_alter_partitions_sync = 2;
set replication_alter_partitions_sync=0;
set replication_alter_partitions_sync=1;
SET replication_alter_partitions_sync=2;
set s3_truncate_on_insert=1;
set schema_inference_make_columns_nullable=0;
set schema_inference_make_columns_nullable=1;
SET select_sequential_consistency = 1;
SET select_sequential_consistency=0;
SET select_sequential_consistency=1;
SET send_logs_level = 'error';
set send_logs_level = 'error';
SET send_logs_level = 'fatal';
set send_logs_level = 'fatal';
SET send_logs_level = 'warning';
SET send_logs_level='error';
SET send_logs_level='fatal';
SET session_timezone = 'Africa/Juba';
SET session_timezone = 'Asia/Novosibirsk';
SET session_timezone = 'Etc/UTC';
SET session_timezone = 'Europe/Amsterdam';
SET session_timezone = 'UTC';
SET session_timezone = '';
SET set_overflow_mode = 'throw';
set short_circuit_function_evaluation = 'enable';
SET short_circuit_function_evaluation = 'force_enable';
SET short_circuit_function_evaluation='enable';
set short_circuit_function_evaluation='force_enable';
SET show_table_uuid_in_table_create_query_if_not_nil=1;
SET single_join_prefer_left_table = 0;
SET skip_download_if_exceeds_query_cache=1;
SET SQL_AUTO_IS_NULL = 0;
SET system_events_show_zero_values = 0;
SET system_events_show_zero_values = 1;
SET system_events_show_zero_values = true;
set throw_on_unsupported_query_inside_transaction=0;
set throw_on_unsupported_query_inside_transaction=1;
SET throw_on_unsupported_query_inside_transaction=1;
SET timeout_before_checking_execution_speed = 0;
SET timeout_overflow_mode = 'break';
SET timeout_overflow_mode='break';
SET totals_auto_threshold = 0.5;
SET totals_mode = 'after_having_auto';
SET totals_mode = 'after_having_exclusive';
SET totals_mode = 'after_having_inclusive';
SET totals_mode = 'before_having';
set transaction snapshot 1000000000000000;
set transaction snapshot 1;
set transaction snapshot 3;
set transaction snapshot 5;
SET transform_null_in = 0;
SET transform_null_in = 1;
set transform_null_in = 1;
SET union_default_mode = 'DISTINCT';
SET union_default_mode='ALL';
SET union_default_mode='DISTINCT';
set use_hedged_requests = 0;
SET use_hedged_requests=0;
SET use_hedged_requests=1;
SET use_index_for_in_with_subqueries = 1;
SET use_query_cache = 1;
set use_structure_from_insertion_table_in_table_functions = 1;
set use_structure_from_insertion_table_in_table_functions=2;
SET use_uncompressed_cache = 0;
SET validate_polygons = 0;
SET wait_for_async_insert = 0;
system disable failpoint replicated_commit_zk_fail_after_op;
system disable failpoint replicated_merge_tree_commit_zk_fail_when_recovering_from_hw_fault;
SYSTEM DISABLE FAILPOINT use_delayed_remote_source;
SYSTEM DROP COMPILED EXPRESSION CACHE;
SYSTEM DROP FILESYSTEM CACHE;
SYSTEM DROP MARK CACHE;
system drop mark cache;
SYSTEM DROP QUERY CACHE;
system drop schema cache for file;
SYSTEM ENABLE FAILPOINT prefetched_reader_pool_failpoint;
system enable failpoint replicated_merge_tree_commit_zk_fail_after_op;
system enable failpoint replicated_merge_tree_commit_zk_fail_when_recovering_from_hw_fault;
system enable failpoint replicated_merge_tree_insert_quorum_fail_0;
SYSTEM ENABLE FAILPOINT use_delayed_remote_source;
SYSTEM FLUSH ASYNC INSERT QUEUE;
SYSTEM FLUSH DISTRIBUTED dist;
SYSTEM FLUSH DISTRIBUTED check_system_tables;
SYSTEM FLUSH DISTRIBUTED demo_loan_01568_dist;
system flush distributed dist;
system flush distributed dist_01293;
system flush distributed dist_01555;
system flush distributed dist_01643;
SYSTEM FLUSH DISTRIBUTED dist_01683;
SYSTEM FLUSH DISTRIBUTED dist_01781;
SYSTEM FLUSH DISTRIBUTED dist_02482;
SYSTEM FLUSH DISTRIBUTED dist_test_01040;
SYSTEM FLUSH DISTRIBUTED distributed;
SYSTEM FLUSH DISTRIBUTED distributed_00952;
SYSTEM FLUSH DISTRIBUTED distributed_01099_b;
system flush distributed on cluster test_shard_localhost db_01294.dist_01294;
system flush distributed t_l5ydey;
SYSTEM FLUSH DISTRIBUTED test_dist_02536;
SYSTEM FLUSH LOGS;
system flush logs;
SYSTEM RELOAD DICTIONARIES ON CLUSTER;
SYSTEM RELOAD DICTIONARIES;
system reload dictionaries;
SYSTEM RELOAD DICTIONARY `foo 1234`.dict;
system reload dictionary db_01527_ranges.dict;
SYSTEM RELOAD DICTIONARY dict;
SYSTEM RELOAD DICTIONARY dict_db_01036.dict;
SYSTEM RELOAD DICTIONARY dict_db_01225.dict;
SYSTEM RELOAD DICTIONARY dict_db_01254.dict;
SYSTEM RELOAD DICTIONARY dict_flat_simple;
SYSTEM RELOAD DICTIONARY dict_hashed_simple_auto_convert;
SYSTEM RELOAD DICTIONARY dict_hashed_simple_Decimal128;
SYSTEM RELOAD DICTIONARY dict_hashed_simple_Float32;
SYSTEM RELOAD DICTIONARY dict_hashed_simple_String;
SYSTEM RELOAD DICTIONARY dict_sharded;
SYSTEM RELOAD DICTIONARY dict_sharded_multi;
SYSTEM RELOAD dictionary regexp_dict1;
SYSTEM RELOAD DICTIONARY test_complex_dictionary_10_shards;
SYSTEM RELOAD DICTIONARY test_complex_dictionary_load_factor;
SYSTEM RELOAD DICTIONARY test_dictionary;
SYSTEM RELOAD DICTIONARY test_dictionary_10_shards;
SYSTEM RELOAD DICTIONARY test_dictionary_10_shards_incremental;
SYSTEM RELOAD DICTIONARY test_dictionary_10_shards_nullable;
SYSTEM RELOAD DICTIONARY test_dictionary_10_shards_string;
SYSTEM RELOAD DICTIONARY test_dictionary_load_factor;
SYSTEM RELOAD DICTIONARY test_dictionary_load_factor_nullable;
SYSTEM RELOAD DICTIONARY test_sparse_dictionary_load_factor;
system restart replica rmt;
system restart replica shard_0.to;
SYSTEM RESTART REPLICA test_alter_r1;
SYSTEM RESTART REPLICA test_alter_r2;
SYSTEM RESTART REPLICAS;
system start distributed sends dist_01293;
system start distributed sends on cluster test_shard_localhost db_01294.dist_01294;
SYSTEM START FETCHES quorum1;
SYSTEM START FETCHES quorum3;
SYSTEM START FETCHES r2;
SYSTEM START FETCHES sqllt.table;
SYSTEM START MERGES 02581_trips;
SYSTEM START MERGES data_01660;
SYSTEM START MERGES dst;
SYSTEM START MERGES limited_merge_table;
SYSTEM START MERGES mt;
SYSTEM START MERGES mt_01451;
system start merges mut;
system start merges nested_smt;
SYSTEM START MERGES replacing_table;
system start merges rmt2;
SYSTEM START MERGES sites;
SYSTEM START MERGES skip_idx_comp_parts;
SYSTEM START MERGES sqllt.table;
SYSTEM START MERGES t;
SYSTEM START MERGES t_json;
SYSTEM START MERGES t_json_sparse;
SYSTEM START MERGES t_json_wide_parts;
SYSTEM START MERGES t_parts_profile_events;
SYSTEM START MERGES t_proj_external;
SYSTEM START MERGES t_sparse_full;
system start merges test_table;
SYSTEM START MERGES tt_01373;
SYSTEM START MERGES ttl;
SYSTEM START MERGES ttl_table;
SYSTEM START merges wide_to_comp;
SYSTEM START MOVES sqllt.table;
SYSTEM START REPLICATED SENDS r1;
SYSTEM START REPLICATED SENDS r2;
system start replicated sends rmt1;
system start replicated sends rmt2;
SYSTEM START REPLICATED SENDS sqllt.table;
SYSTEM START REPLICATION QUEUES checksums_r2;
SYSTEM START REPLICATION QUEUES checksums_r3;
SYSTEM START REPLICATION QUEUES execute_on_single_replica_r2;
SYSTEM START REPLICATION QUEUES wikistat2;
SYSTEM START REPLICATION QUEUES wrong_metadata;
SYSTEM START REPLICATION QUEUES wrong_metadata_wide;
SYSTEM START TTL MERGES prop_table;
SYSTEM START TTL MERGES recompression_table;
SYSTEM START TTL MERGES sqllt.table;
system start ttl merges ttl;
system start ttl merges ttl_test_02129;
system stop cleanup rmt1;
system stop cleanup rmt3;
system stop cleanup rmt;
system stop distributed sends buf;
SYSTEM STOP DISTRIBUTED SENDS check_system_tables;
system stop distributed sends dist;
system stop distributed sends dist_01293;
system stop distributed sends dist_01555;
system stop distributed sends dist_01643;
system stop distributed sends dist_01670;
SYSTEM STOP DISTRIBUTED SENDS dist_01781;
SYSTEM STOP DISTRIBUTED SENDS dist_02482;
SYSTEM STOP DISTRIBUTED SENDS distributed_01099_b;
system stop distributed sends on cluster test_shard_localhost db_01294.dist_01294;
SYSTEM STOP DISTRIBUTED SENDS test_dist_02536;
SYSTEM STOP FETCHES quorum1;
SYSTEM STOP FETCHES quorum3;
SYSTEM STOP FETCHES r2;
SYSTEM STOP FETCHES sqllt.table;
SYSTEM STOP MERGES checkouts;
SYSTEM STOP MERGES data;
system stop merges data;
SYSTEM STOP MERGES data_01660;
SYSTEM STOP MERGES data_02201;
system stop merges data_order_by_proj_comp;
system stop merges data_order_by_proj_incomp;
system stop merges data_proj_order_by_comp;
system stop merges data_proj_order_by_incomp;
system stop merges dist_t;
SYSTEM STOP MERGES dst;
SYSTEM STOP MERGES event_types;
SYSTEM STOP MERGES join_on_disk;
SYSTEM STOP MERGES limited_merge_table;
SYSTEM STOP MERGES logins;
SYSTEM STOP MERGES merge_tree_deduplication;
SYSTEM STOP MERGES mt;
SYSTEM STOP MERGES mt_01451;
system stop merges mut;
system stop merges nested_smt;
system stop merges order;
system stop merges order_by_const;
SYSTEM STOP MERGES partitioned_table;
SYSTEM STOP MERGES replacing_m3;
SYSTEM STOP MERGES replacing_table;
system stop merges rmt1;
system stop merges rmt2;
SYSTEM STOP MERGES session_events;
system stop merges simple_agg_groupArrayLastArray;
SYSTEM STOP MERGES sites;
SYSTEM STOP MERGES skip_idx_comp_parts;
SYSTEM STOP MERGES sqllt.table;
system stop merges t1;
system stop merges t2;
system stop merges t3;
system stop merges t4;
system stop merges t5;
system stop merges t6;
system stop merges t;
SYSTEM STOP MERGES t;
SYSTEM STOP MERGES t_cache_sparse;
SYSTEM STOP MERGES t_dst;
SYSTEM STOP MERGES t_json;
SYSTEM STOP MERGES t_json_17;
SYSTEM STOP MERGES t_json_sparse;
SYSTEM STOP MERGES t_json_wide_parts;
SYSTEM STOP MERGES t_parts_profile_events;
SYSTEM STOP MERGES t_proj_external;
SYSTEM STOP MERGES t_read_in_order;
SYSTEM STOP MERGES t_sparse;
SYSTEM STOP MERGES t_sparse_02235;
SYSTEM STOP MERGES t_sparse_distinct;
SYSTEM STOP MERGES t_sparse_full;
SYSTEM STOP MERGES t_sparse_intersect;
SYSTEM STOP MERGES t_src;
SYSTEM STOP MERGES tab;
SYSTEM STOP MERGES table_with_defaults_on_aliases;
SYSTEM STOP MERGES tbl;
SYSTEM STOP MERGES test;
system stop merges test_block_mismatch;
system stop merges test_block_mismatch_sk1;
system stop merges test_block_mismatch_sk2;
SYSTEM STOP MERGES test_table_join_2;
SYSTEM STOP MERGES too_many_parts;
system stop merges ts;
SYSTEM STOP REPLICATION QUEUES wrong_metadata_wide;
SYSTEM STOP TTL MERGES prop_table;
SYSTEM STOP TTL MERGES recompression_table;
SYSTEM STOP TTL MERGES recompression_table_compact;
SYSTEM STOP TTL MERGES sqllt.table;
system stop ttl merges ttl;
system stop ttl merges ttl_test_02129;
system sync file cache;
SYSTEM SYNC REPLICA adaptive_granularity_alter1;
SYSTEM SYNC REPLICA adaptive_granularity_alter2;
SYSTEM SYNC REPLICA alter_compression_codec1;
SYSTEM SYNC REPLICA alter_compression_codec2;
SYSTEM SYNC REPLICA byte_identical_r1;
SYSTEM SYNC REPLICA byte_identical_r2;
SYSTEM SYNC REPLICA cast2;
SYSTEM SYNC REPLICA checksums_r2;
SYSTEM SYNC REPLICA checksums_r3;
SYSTEM SYNC REPLICA clear_column2;
SYSTEM SYNC REPLICA compression_codec_multiple_replicated1;
SYSTEM SYNC REPLICA compression_codec_multiple_replicated2;
SYSTEM SYNC REPLICA compression_codec_replicated2;
system sync replica dst2;
SYSTEM SYNC REPLICA empty1;
SYSTEM SYNC REPLICA execute_on_single_replica_r1;
SYSTEM SYNC REPLICA minmax_idx;
SYSTEM SYNC REPLICA minmax_idx_r;
system sync replica mut pull;
system sync replica mut;
SYSTEM SYNC REPLICA mutate_and_zero_copy_replication2;
SYSTEM SYNC REPLICA mutation_2;
SYSTEM SYNC REPLICA quorum2;
SYSTEM SYNC REPLICA quorum3;
SYSTEM SYNC REPLICA r1;
SYSTEM SYNC REPLICA r2;
SYSTEM SYNC REPLICA r_prop_table1;
SYSTEM SYNC REPLICA r_prop_table2;
TRUNCATE DATABASE test_truncate_database;
TRUNCATE defaults;
TRUNCATE full_duplicates;
TRUNCATE partial_duplicates;
TRUNCATE TABLE 02005_test_table;
TRUNCATE TABLE 02416_test;
truncate table arr_tests_visits;
TRUNCATE TABLE arrays_test;
TRUNCATE TABLE bug_14144;
TRUNCATE TABLE compression_codec_multiple;
TRUNCATE TABLE compression_codec_multiple_log;
TRUNCATE TABLE compression_codec_multiple_replicated1;
TRUNCATE TABLE compression_codec_multiple_tiny_log;
truncate table data;
truncate table data_02491;
TRUNCATE TABLE test_01040;
truncate table test_02302;
TRUNCATE TABLE test_log;
TRUNCATE TABLE test_table;
TRUNCATE TABLE test_table_2;
TRUNCATE TABLE times;
TRUNCATE TABLE tmp;
TRUNCATE TABLE trend;
TRUNCATE TABLE truncate_test_log;
TRUNCATE TABLE truncate_test_materialized_view;
TRUNCATE TABLE truncate_test_memory;
TRUNCATE TABLE truncate_test_merge_tree;
TRUNCATE TABLE truncate_test_set;
TRUNCATE TABLE truncate_test_stripe_log;
TRUNCATE TABLE truncate_test_tiny_log;
TRUNCATE TABLE type_json_dst;
TRUNCATE TABLE type_json_src;
truncate temporary table test_00670;
TRUNCATE test_table;
truncate trunc;
TRUNCATE truncate_test;
undrop table 02681_undrop_detach;
undrop table 02681_undrop_distributed;
undrop table 02681_undrop_log;
undrop table 02681_undrop_mergetree;
undrop table 02681_undrop_multiple;
undrop table 02681_undrop_no_uuid_on_cluster on cluster test_shard_localhost format Null;
undrop table 02681_undrop_replicatedmergetree;
undrop table 02681_undrop_uuid_on_cluster on cluster test_shard_localhost format Null;